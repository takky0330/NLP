{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_BunshoAC_IIC.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMon9nzLi6Vfxlo90NXF9tK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ea8b6d9605ec46419ff2e3c1bd1832af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d2f0489aaf3f4e0b80eff4363cc97f30",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b433116deda845f09bb12b18f50d146b",
              "IPY_MODEL_ff2760d47d1349768f9319a6ec150c7d"
            ]
          }
        },
        "d2f0489aaf3f4e0b80eff4363cc97f30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b433116deda845f09bb12b18f50d146b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5d5dd2bb74d54f65b316a8b6d7b8b3f9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e12ee6c64ce24a5ca615b64cfdfc9be7"
          }
        },
        "ff2760d47d1349768f9319a6ec150c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_78018b121af146f1859eb8aef4ca908e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:01&lt;00:00, 366B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95c39cc469ae47558061e0e79fcec4df"
          }
        },
        "5d5dd2bb74d54f65b316a8b6d7b8b3f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e12ee6c64ce24a5ca615b64cfdfc9be7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "78018b121af146f1859eb8aef4ca908e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95c39cc469ae47558061e0e79fcec4df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50d55bb3a02248328a1f9b5fb2289ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_563e835fef9c4619b35c7c8f051af6d2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_71541607efe64ea2b43b26a8444b9f3f",
              "IPY_MODEL_44b81b1812424c5e83dead360214a107"
            ]
          }
        },
        "563e835fef9c4619b35c7c8f051af6d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71541607efe64ea2b43b26a8444b9f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e99cd8c5006045c69570e18367745c64",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 445021143,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 445021143,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c3585b995644a3b81effc6adc212294"
          }
        },
        "44b81b1812424c5e83dead360214a107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_542f92f9d78545a298c80f4945a44b5e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 445M/445M [00:11&lt;00:00, 37.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ca7bde982774d408f6fe92c434357a0"
          }
        },
        "e99cd8c5006045c69570e18367745c64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c3585b995644a3b81effc6adc212294": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "542f92f9d78545a298c80f4945a44b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ca7bde982774d408f6fe92c434357a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takky0330/NLP/blob/master/BERT_BunshoAC_IIC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PY5RSXia7M4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "1a10befd-71c6-463f-8658-c8614947a53a"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "SEED_VALUE = 1234  # これはなんでも良い\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED_VALUE)\n",
        "random.seed(SEED_VALUE)\n",
        "np.random.seed(SEED_VALUE)\n",
        "torch.manual_seed(SEED_VALUE)  # PyTorchを使う場合"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ff1c7d99510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0wW9fdUbbs_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8066dfeb-5b86-4a04-a57c-83db4f41dac3"
      },
      "source": [
        "# GPUの使用確認：True or False\n",
        "torch.cuda.is_available()\n",
        "\n",
        "# TrueならGPU使用可能"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdOO86Ltbwo-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MeCabとtransformersの用意\n",
        "!apt install aptitude swig\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3\n",
        "!pip install transformers==2.9.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEkdZtzCQF6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchtext  # torchtextを使用\n",
        "from transformers.modeling_bert import BertModel\n",
        "from transformers.tokenization_bert_japanese import BertJapaneseTokenizer\n",
        "\n",
        "# 日本語BERTの分かち書き用tokenizerです\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained(\n",
        "    'bert-base-japanese-whole-word-masking')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Je3nNn4Q6O8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "3ccc7bfb-1a4c-4231-cf81-8234a56e7804"
      },
      "source": [
        "# body に解析対象の文をセットすればよい （label は使わないなぁ…）\n",
        "import pandas as pd\n",
        "\n",
        "!wget \"https://robotdiver.takky.org/rd/malss/22_c4ev5t48ul6jl8io4m8c97hok7/c4ev5t48ul6jl8io4m8c97hok7_明治Q7.rd\"\n",
        "text = pd.read_csv(\"c4ev5t48ul6jl8io4m8c97hok7_明治Q7.rd\", encoding='utf-8', sep='\\t', index_col=0)\n",
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-22 08:06:46--  https://robotdiver.takky.org/rd/malss/22_c4ev5t48ul6jl8io4m8c97hok7/c4ev5t48ul6jl8io4m8c97hok7_%E6%98%8E%E6%B2%BBQ7.rd\n",
            "Resolving robotdiver.takky.org (robotdiver.takky.org)... 13.70.40.33\n",
            "Connecting to robotdiver.takky.org (robotdiver.takky.org)|13.70.40.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11324 (11K)\n",
            "Saving to: ‘c4ev5t48ul6jl8io4m8c97hok7_明治Q7.rd.5’\n",
            "\n",
            "c4ev5t48ul6jl8io4m8 100%[===================>]  11.06K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-05-22 08:06:47 (136 MB/s) - ‘c4ev5t48ul6jl8io4m8c97hok7_明治Q7.rd.5’ saved [11324/11324]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>回答者ID</th>\n",
              "      <th>Q7S1 コレステロール値への対策</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>24005038</td>\n",
              "      <td>トクホのお茶</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>24423493</td>\n",
              "      <td>食事に気をつける</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>18877833</td>\n",
              "      <td>食生活に注意する</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>24292715</td>\n",
              "      <td>食べない</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>24319736</td>\n",
              "      <td>食べ物</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>944</th>\n",
              "      <td>14341739</td>\n",
              "      <td>サプリを飲む</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>945</th>\n",
              "      <td>20122747</td>\n",
              "      <td>サラダ油を使わない</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>946</th>\n",
              "      <td>21510694</td>\n",
              "      <td>油物をあまり食べない</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>947</th>\n",
              "      <td>22532355</td>\n",
              "      <td>コレステロール値の高いイクラ隆一の子、魚の子などはひかえる。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>955</th>\n",
              "      <td>18129260</td>\n",
              "      <td>野菜を食べる</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>320 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        回答者ID               Q7S1 コレステロール値への対策\n",
              "5    24005038                          トクホのお茶\n",
              "8    24423493                        食事に気をつける\n",
              "12   18877833                        食生活に注意する\n",
              "13   24292715                            食べない\n",
              "14   24319736                             食べ物\n",
              "..        ...                             ...\n",
              "944  14341739                          サプリを飲む\n",
              "945  20122747                       サラダ油を使わない\n",
              "946  21510694                      油物をあまり食べない\n",
              "947  22532355  コレステロール値の高いイクラ隆一の子、魚の子などはひかえる。\n",
              "955  18129260                          野菜を食べる\n",
              "\n",
              "[320 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XOkbYLqyNIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# カテゴリーの辞書を作成\n",
        "dic_id2cat = dict(zip(list(range(len(categories))), categories))\n",
        "dic_cat2id = dict(zip(categories, list(range(len(categories)))))\n",
        "\n",
        "# DataFrameにカテゴリーindexの列を作成\n",
        "df[\"label_index\"] = df[\"label\"].map(dic_cat2id)\n",
        "\n",
        "# label列を消去し、text, indexの順番にする\n",
        "df = df.loc[:, [\"text\", \"label_index\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndDjIZUlyP-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 順番をシャッフルする\n",
        "df = df.sample(frac=1, random_state=123).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbGINxHHyS3g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ef5b706f-7bdd-4805-be1e-07925615728f"
      },
      "source": [
        "# tsvファイルで保存する\n",
        "\n",
        "# 全体の2割の文章数\n",
        "len_0_2 = len(df) // 5\n",
        "\n",
        "# 前から2割をテストデータとする\n",
        "df[:len_0_2].to_csv(\"./test.tsv\", sep='\\t', index=False, header=None)\n",
        "print(df[:len_0_2].shape)\n",
        "\n",
        "# 前2割からを訓練&検証データとする\n",
        "df[len_0_2:].to_csv(\"./train_eval.tsv\", sep='\\t', index=False, header=None)\n",
        "print(df[len_0_2:].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1475, 2)\n",
            "(5901, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9un4vmdyuhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# データを読み込んだときに、読み込んだ内容に対して行う処理を定義します\n",
        "\n",
        "max_length = 512  # 東北大学_日本語版の最大の単語数（サブワード数）は512\n",
        "\n",
        "\n",
        "def tokenizer_512(input_text):\n",
        "    \"\"\"torchtextのtokenizerとして扱えるように、512単語のpytorchでのencodeを定義。ここで[0]を指定し忘れないように\"\"\"\n",
        "    return tokenizer.encode(input_text, max_length=512, return_tensors='pt')[0]\n",
        "\n",
        "\n",
        "TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_512, use_vocab=False, lower=False,\n",
        "                            include_lengths=True, batch_first=True, fix_length=max_length, pad_token=0)\n",
        "# 注意：tokenize=tokenizer.encodeと、.encodeをつけます。padding[PAD]のindexが0なので、0を指定します。\n",
        "\n",
        "LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "# (注釈)：各引数を再確認\n",
        "# sequential: データの長さが可変か？文章は長さがいろいろなのでTrue.ラベルはFalse\n",
        "# tokenize: 文章を読み込んだときに、前処理や単語分割をするための関数を定義\n",
        "# use_vocab：単語をボキャブラリーに追加するかどうか\n",
        "# lower：アルファベットがあったときに小文字に変換するかどうか\n",
        "# include_length: 文章の単語数のデータを保持するか\n",
        "# batch_first：ミニバッチの次元を用意するかどうか\n",
        "# fix_length：全部の文章をfix_lengthと同じ長さになるように、paddingします\n",
        "# init_token, eos_token, pad_token, unk_token：文頭、文末、padding、未知語に対して、どんな単語を与えるかを指定"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOAAmUgsyx_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 各tsvファイルを読み込み、分かち書きをしてdatasetにします\n",
        "# 少し時間がかかります\n",
        "# train_eval：5901個、test：1475個\n",
        "dataset_train_eval, dataset_test = torchtext.data.TabularDataset.splits(\n",
        "    path='.', train='train_eval.tsv', test='test.tsv', format='tsv', fields=[('Text', TEXT), ('Label', LABEL)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtbVqDgyy2L_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "8854f716-e2fa-4576-ffbc-3e284f221bc3"
      },
      "source": [
        "# torchtext.data.Datasetのsplit関数で訓練データと検証データを分ける\n",
        "# train_eval：5901個、test：1475個\n",
        "\n",
        "dataset_train, dataset_eval = dataset_train_eval.split(\n",
        "    split_ratio=1.0 - 1475/5901, random_state=random.seed(1234))\n",
        "\n",
        "# datasetの長さを確認してみる\n",
        "print(dataset_train.__len__())\n",
        "print(dataset_eval.__len__())\n",
        "print(dataset_test.__len__())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4426\n",
            "1475\n",
            "1475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-JZrkmN0OU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DataLoaderを作成します（torchtextの文脈では単純にiteraterと呼ばれています）\n",
        "batch_size = 16  # BERTでは16、32あたりを使用する\n",
        "\n",
        "dl_train = torchtext.data.Iterator(\n",
        "    dataset_train, batch_size=batch_size, train=True)\n",
        "\n",
        "dl_eval = torchtext.data.Iterator(\n",
        "    dataset_eval, batch_size=batch_size, train=False, sort=False)\n",
        "\n",
        "dl_test = torchtext.data.Iterator(\n",
        "    dataset_test, batch_size=batch_size, train=False, sort=False)\n",
        "\n",
        "# 辞書オブジェクトにまとめる\n",
        "dataloaders_dict = {\"train\": dl_train, \"val\": dl_eval}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjPzOKZy0SV-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "ea8b6d9605ec46419ff2e3c1bd1832af",
            "d2f0489aaf3f4e0b80eff4363cc97f30",
            "b433116deda845f09bb12b18f50d146b",
            "ff2760d47d1349768f9319a6ec150c7d",
            "5d5dd2bb74d54f65b316a8b6d7b8b3f9",
            "e12ee6c64ce24a5ca615b64cfdfc9be7",
            "78018b121af146f1859eb8aef4ca908e",
            "95c39cc469ae47558061e0e79fcec4df",
            "50d55bb3a02248328a1f9b5fb2289ebd",
            "563e835fef9c4619b35c7c8f051af6d2",
            "71541607efe64ea2b43b26a8444b9f3f",
            "44b81b1812424c5e83dead360214a107",
            "e99cd8c5006045c69570e18367745c64",
            "6c3585b995644a3b81effc6adc212294",
            "542f92f9d78545a298c80f4945a44b5e",
            "0ca7bde982774d408f6fe92c434357a0"
          ]
        },
        "outputId": "35305695-9c31-4b69-fb26-e7a838a2dd47"
      },
      "source": [
        "from transformers.modeling_bert import BertModel\n",
        "\n",
        "# BERTの日本語学習済みパラメータのモデルです\n",
        "model = BertModel.from_pretrained('bert-base-japanese-whole-word-masking')\n",
        "model.eval()\n",
        "print('ネットワーク設定完了')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea8b6d9605ec46419ff2e3c1bd1832af",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50d55bb3a02248328a1f9b5fb2289ebd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=445021143.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ネットワーク設定完了\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-jY1LWB0XLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BERTでベクトル化する関数を定義\n",
        "\n",
        "\n",
        "def vectorize_with_bert(net, dataloader):\n",
        "\n",
        "    # GPUが使えるかを確認\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"使用デバイス：\", device)\n",
        "    print('-----start-------')\n",
        "\n",
        "    # ネットワークをGPUへ\n",
        "    net.to(device)\n",
        "\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # ミニバッチのサイズ\n",
        "    batch_size = dataloader.batch_size\n",
        "\n",
        "    # データローダーからミニバッチを取り出すループ\n",
        "    for index, batch in enumerate(dataloader):\n",
        "        # batchはTextとLableの辞書オブジェクト\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        inputs = batch.Text[0].to(device)  # 文章\n",
        "        labels = batch.Label.to(device)  # ラベル\n",
        "\n",
        "        # 順伝搬（forward）計算\n",
        "        with torch.set_grad_enabled(False):\n",
        "\n",
        "            # Berに入力\n",
        "            result = net(inputs)\n",
        "\n",
        "            # sequence_outputの先頭の単語ベクトルを抜き出す\n",
        "            vec_0 = result[0]  # 最初の0がsequence_outputを示す\n",
        "            vec_0 = vec_0[:, 0, :]  # 全バッチ。先頭0番目の単語の全768要素\n",
        "            vec_0 = vec_0.view(-1, 768)  # sizeを[batch_size, hidden_size]に変換\n",
        "\n",
        "            # ベクトル化したデータをtorchリストにまとめる\n",
        "            if index == 0:\n",
        "                list_text = vec_0\n",
        "                list_label = labels\n",
        "            else:\n",
        "                list_text = torch.cat([list_text, vec_0], dim=0)\n",
        "                list_label = torch.cat([list_label, labels], dim=0)\n",
        "\n",
        "    return list_text, list_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8xTafhC0eXu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "6a28e75e-a42e-4ee2-df86-e6d00fc3300b"
      },
      "source": [
        "# DataLoaderをベクトル化版に変換\n",
        "# 少し時間がかかります5分弱\n",
        "\n",
        "list_text_train, list_label_train = vectorize_with_bert(model, dl_train)\n",
        "list_text_eval, list_label_eval = vectorize_with_bert(model, dl_eval)\n",
        "list_text_test, list_label_test = vectorize_with_bert(model, dl_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "使用デバイス： cuda:0\n",
            "-----start-------\n",
            "使用デバイス： cuda:0\n",
            "-----start-------\n",
            "使用デバイス： cuda:0\n",
            "-----start-------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHByOUsN0h05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torchのリストをDatasetに変換\n",
        "\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "dataset_bert_train = TensorDataset(list_label_train.view(-1, 1), list_text_train)\n",
        "dataset_bert_eval = TensorDataset(list_label_eval.view(-1, 1), list_text_eval)\n",
        "dataset_bert_test = TensorDataset(list_label_test.view(-1, 1), list_text_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNTZlSSn3T9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataloaderにする\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 1024\n",
        "\n",
        "dl_bert_train = DataLoader(\n",
        "    dataset_bert_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "# drop_lastは最後のミニバッチがbatch_sizeに足りない場合は無視する\n",
        "\n",
        "dl_bert_eval = DataLoader(\n",
        "    dataset_bert_eval, batch_size=batch_size, shuffle=False)\n",
        "dl_bert_test = DataLoader(\n",
        "    dataset_bert_test, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak7L09Hj3XM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "OVER_CLUSTRING_RATE = 10\n",
        "\n",
        "\n",
        "class NetIIC(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetIIC, self).__init__()\n",
        "\n",
        "        # multi-headは今回しない\n",
        "        self.conv1 = nn.Conv1d(1, 400, kernel_size=768, stride=1, padding=0)\n",
        "        self.bn1 = nn.BatchNorm1d(400)\n",
        "        self.conv2 = nn.Conv1d(1, 300, kernel_size=400, stride=1, padding=0)\n",
        "        self.bn2 = nn.BatchNorm1d(300)\n",
        "        self.conv3 = nn.Conv1d(1, 300, kernel_size=300, stride=1, padding=0)\n",
        "        self.bn3 = nn.BatchNorm1d(300)\n",
        "\n",
        "        self.fc1 = nn.Linear(300, 250)\n",
        "        self.bnfc1 = nn.BatchNorm1d(250)\n",
        "\n",
        "        # livedoorニュースの9カテゴリに対応するかな？と期待する9分類\n",
        "        self.fc2 = nn.Linear(250, 9)\n",
        "\n",
        "        # overclustering\n",
        "        # 実際の想定よりも多めにクラスタリングさせることで、ネットワークで微細な変化を捉えられるようにする\n",
        "        self.fc2_overclustering = nn.Linear(250, 9*OVER_CLUSTRING_RATE)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), 1, -1)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "\n",
        "        x = x.view(x.size(0), 1, -1)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "\n",
        "        x = x.view(x.size(0), 1, -1)\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x_prefinal = F.relu(self.bnfc1(self.fc1(x)))\n",
        "\n",
        "        # multi-headは使わず\n",
        "        y = F.softmax(self.fc2(x_prefinal), dim=1)\n",
        "        y_overclustering = F.softmax(self.fc2_overclustering(\n",
        "            x_prefinal), dim=1)  # overclustering\n",
        "\n",
        "        return y, y_overclustering"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYI8J6Zd3aMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "\n",
        "def weight_init(m):\n",
        "    \"\"\"重み初期化\"\"\"\n",
        "    if isinstance(m, nn.Conv1d):\n",
        "        init.normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.BatchNorm1d):\n",
        "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        # Xavier\n",
        "        # init.xavier_normal_(m.weight.data)\n",
        "\n",
        "        # He\n",
        "        init.kaiming_normal_(m.weight.data)\n",
        "\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCJUyWZJ3d7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IISによる損失関数の定義\n",
        "# 参考：https://github.com/RuABraun/phone-clustering/blob/master/mnist_basic.py\n",
        "import sys\n",
        "\n",
        "\n",
        "def compute_joint(x_out, x_tf_out):\n",
        "    bn, k = x_out.size()\n",
        "    assert (x_tf_out.size(0) == bn and x_tf_out.size(1) == k), '{} {} {} {}'.format(\n",
        "        bn, k, x_tf_out.size(0), x_tf_out.size(1))\n",
        "\n",
        "    p_i_j = x_out.unsqueeze(2) * x_tf_out.unsqueeze(1)  # bn, k, k\n",
        "    p_i_j = p_i_j.sum(dim=0)  # k, k\n",
        "    p_i_j = (p_i_j + p_i_j.t()) / 2.  # symmetrise\n",
        "    p_i_j = p_i_j / p_i_j.sum()  # normalise\n",
        "    return p_i_j\n",
        "\n",
        "\n",
        "def IID_loss(x_out, x_tf_out, EPS=sys.float_info.epsilon):\n",
        "    # has had softmax applied\n",
        "    bs, k = x_out.size()\n",
        "    p_i_j = compute_joint(x_out, x_tf_out)\n",
        "    assert (p_i_j.size() == (k, k))\n",
        "\n",
        "    p_i = p_i_j.sum(dim=1).view(k, 1).expand(k, k)\n",
        "    p_j = p_i_j.sum(dim=0).view(1, k).expand(k, k)\n",
        "\n",
        "    # avoid NaN losses. Effect will get cancelled out by p_i_j tiny anyway\n",
        "    # これはPyTorchのバージョン1.3以上だとエラーになる\n",
        "    # https://discuss.pytorch.org/t/pytorch-1-3-showing-an-error-perhaps-for-loss-computed-from-paired-outputs/68790/3\n",
        "    #p_i_j[(p_i_j < EPS).data] = EPS\n",
        "    #p_j[(p_j < EPS).data] = EPS\n",
        "    #p_i[(p_i < EPS).data] = EPS\n",
        "\n",
        "    p_i_j = torch.where(p_i_j < EPS, torch.tensor(\n",
        "        [EPS], device=p_i_j.device), p_i_j)\n",
        "    p_j = torch.where(p_j < EPS, torch.tensor([EPS], device=p_j.device), p_j)\n",
        "    p_i = torch.where(p_i < EPS, torch.tensor([EPS], device=p_i.device), p_i)\n",
        "\n",
        "    # https://qiita.com/Amanokawa/items/0aa24bc396dd88fb7d2a\n",
        "    # 参考に、重みalphaを追加\n",
        "\n",
        "    alpha = 2.0\n",
        "    loss = (- p_i_j * (torch.log(p_i_j) - alpha *\n",
        "                       torch.log(p_j) - alpha*torch.log(p_i))).sum()\n",
        "\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKYog6wH3g8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# データにノイズを加える関数の定義\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "tensor_std = list_text_train.std(dim=0).to(device)\n",
        "\n",
        "\n",
        "def perturb_data(x):\n",
        "    y = x.clone()\n",
        "    noise = torch.randn(len(tensor_std)).to(device)*tensor_std*2.0\n",
        "    noise = noise.expand(x.shape[0], -1)\n",
        "    y += noise\n",
        "\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8LA_mWh3jQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 学習関数の定義\n",
        "\n",
        "def train(total_epoch, model, train_loader, optimizer, device):\n",
        "\n",
        "    # ネットワークを訓練モードに\n",
        "    model.train()\n",
        "\n",
        "    # 学習率のスケジューラーCosAnnealing\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "        optimizer, T_0=2, T_mult=2, eta_min=0)\n",
        "\n",
        "    for epoch in range(total_epoch):\n",
        "        for batch_idx, (target, data) in enumerate(train_loader):\n",
        "\n",
        "            # 学習率変化\n",
        "            scheduler.step()\n",
        "            \n",
        "            data_perturb = perturb_data(data)  # ノイズを与え、変換したデータを作る\n",
        "\n",
        "            # GPUに送れる場合は送る\n",
        "            data = data.to(device)\n",
        "            data_perturb = data_perturb.to(device)\n",
        "\n",
        "            # 最適化関数の初期化\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # ニューラルネットワークへ入れる\n",
        "            output, output_overclustering = model(data)\n",
        "            output_perturb, output_perturb_overclustering = model(data_perturb)\n",
        "\n",
        "            # 損失の計算\n",
        "            loss1 = IID_loss(output, output_perturb)\n",
        "            loss2 = IID_loss(output_overclustering,\n",
        "                             output_perturb_overclustering)\n",
        "            loss = loss1 + loss2\n",
        "\n",
        "            # 損失を減らすように更新\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # ログ出力\n",
        "        if epoch % 50 == 0:\n",
        "            print('Train Epoch {} \\tLoss1: {:.6f} \\tLoss2: {:.6f} \\tLoss_total: {:.6f}'.format(\n",
        "                epoch, loss1.item(), loss2.item(), loss1.item()+loss2.item()))\n",
        "\n",
        "    return model, optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpgvtd0D3mLa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "6abe67ec-4dca-462d-a75b-68f693cbd489"
      },
      "source": [
        "# 学習の実施(5分弱)\n",
        "\n",
        "# モデルの用意\n",
        "net = NetIIC()\n",
        "net.apply(weight_init)\n",
        "net.to(device)\n",
        "\n",
        "# 最適化関数\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4) \n",
        "\n",
        "total_epoch = 1000\n",
        "\n",
        "model_trained, optimizer = train(\n",
        "    total_epoch, net, dl_bert_train, optimizer, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch 0 \tLoss1: -3.944716 \tLoss2: -7.745652 \tLoss_total: -11.690368\n",
            "Train Epoch 50 \tLoss1: -6.165148 \tLoss2: -10.256249 \tLoss_total: -16.421398\n",
            "Train Epoch 100 \tLoss1: -6.493257 \tLoss2: -11.206728 \tLoss_total: -17.699985\n",
            "Train Epoch 150 \tLoss1: -6.562608 \tLoss2: -11.715666 \tLoss_total: -18.278274\n",
            "Train Epoch 200 \tLoss1: -6.560358 \tLoss2: -12.417967 \tLoss_total: -18.978324\n",
            "Train Epoch 250 \tLoss1: -6.552682 \tLoss2: -12.592127 \tLoss_total: -19.144809\n",
            "Train Epoch 300 \tLoss1: -6.566082 \tLoss2: -13.142930 \tLoss_total: -19.709012\n",
            "Train Epoch 350 \tLoss1: -6.562592 \tLoss2: -13.185946 \tLoss_total: -19.748537\n",
            "Train Epoch 400 \tLoss1: -6.542658 \tLoss2: -13.153091 \tLoss_total: -19.695749\n",
            "Train Epoch 450 \tLoss1: -6.567782 \tLoss2: -13.166708 \tLoss_total: -19.734490\n",
            "Train Epoch 500 \tLoss1: -6.567127 \tLoss2: -13.224188 \tLoss_total: -19.791315\n",
            "Train Epoch 550 \tLoss1: -6.557654 \tLoss2: -13.164039 \tLoss_total: -19.721693\n",
            "Train Epoch 600 \tLoss1: -6.575311 \tLoss2: -13.198984 \tLoss_total: -19.774295\n",
            "Train Epoch 650 \tLoss1: -6.558971 \tLoss2: -13.172503 \tLoss_total: -19.731474\n",
            "Train Epoch 700 \tLoss1: -6.557375 \tLoss2: -13.133028 \tLoss_total: -19.690403\n",
            "Train Epoch 750 \tLoss1: -6.567755 \tLoss2: -13.199617 \tLoss_total: -19.767372\n",
            "Train Epoch 800 \tLoss1: -6.559557 \tLoss2: -13.179523 \tLoss_total: -19.739080\n",
            "Train Epoch 850 \tLoss1: -6.566164 \tLoss2: -13.111540 \tLoss_total: -19.677704\n",
            "Train Epoch 900 \tLoss1: -6.576500 \tLoss2: -13.226315 \tLoss_total: -19.802815\n",
            "Train Epoch 950 \tLoss1: -6.564157 \tLoss2: -13.215998 \tLoss_total: -19.780155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSdIpQTn3pTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデル分類のクラスターの結果を確認する\n",
        "import numpy as np\n",
        "\n",
        "# ミニバッチサイズ1のテスト用のDataLoaderを用意\n",
        "dl_bert_test = DataLoader(\n",
        "    dataset_bert_test, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "\n",
        "    out_targs = []\n",
        "    ref_targs = []\n",
        "\n",
        "    # 出力用のリストを用意\n",
        "    total_num = len(test_loader)\n",
        "    # index, (target_label, inferenced_label)\n",
        "    output_list = np.zeros((total_num, 2))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (target, data) in enumerate(test_loader):\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            outputs, outputs_overclustering = model(data)\n",
        "\n",
        "            # 分類結果をリストに追加\n",
        "            out_targs.append(outputs.argmax(dim=1).cpu())\n",
        "            ref_targs.append(target[0].cpu())\n",
        "\n",
        "            # 結果をリストにまとめる\n",
        "            output_list[batch_idx, 0] = target[0][0].cpu()  # 正解ラベル\n",
        "            output_list[batch_idx, 1] = outputs.argmax(dim=1).cpu()  # 予測ラベル\n",
        "\n",
        "    out_targs = torch.cat(out_targs)\n",
        "    ref_targs = torch.cat(ref_targs)\n",
        "\n",
        "    return out_targs.view(-1, 1).numpy(), ref_targs.numpy(), output_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27NUalWh35vg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# テストデータで推論を実施\n",
        "out_targs, ref_targs, output_list = test(model_trained, device, dl_bert_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8Zh-1CN38rV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "92c216b3-52c3-425e-a714-3ce1aa8a99b4"
      },
      "source": [
        "# 混同行列（的な）を作る\n",
        "matrix = np.zeros((9, 9))\n",
        "\n",
        "# 縦にlivedoorニュースの正解クラスを、横に判定されたクラスの頻度表を作成\n",
        "for i in range(len(out_targs)):\n",
        "    row = ref_targs[i]\n",
        "    col = out_targs[i]\n",
        "    matrix[row][col] += 1\n",
        "\n",
        "np.set_printoptions(suppress=True)\n",
        "print(matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 13.  24.  14.   2.  32.  12.  50.   1.  30.]\n",
            " [ 20.   2.  61.  32.   4.  16.  38.   0.   1.]\n",
            " [  7.   3.  17.   5.  34.   4.  24.   0.   8.]\n",
            " [ 57.   1.   2.   0.   0.  46.   2.  59.   1.]\n",
            " [  2.  11.   3.   1.  14.   0.   2.   1. 133.]\n",
            " [ 30.   2.   2.   0.   4.  64.   2.  49.   1.]\n",
            " [  5.   2.  11. 103.   0.  10.  42.   0.   1.]\n",
            " [  9. 145.   7.   2.   2.   6.   3.   4.   3.]\n",
            " [ 68.   5.  29.   9.   7.  37.  17.   3.   2.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ_kshfF4S0r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "2c82ba11-7a91-46e3-c1de-84137176bf04"
      },
      "source": [
        "dic_id2cat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'peachy',\n",
              " 1: 'it-life-hack',\n",
              " 2: 'livedoor-homme',\n",
              " 3: 'sports-watch',\n",
              " 4: 'dokujo-tsushin',\n",
              " 5: 'topic-news',\n",
              " 6: 'smax',\n",
              " 7: 'movie-enter',\n",
              " 8: 'kaden-channel'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d--1MQQW4dSr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "e4380d9f-0eda-40e4-dff5-2f334c3f285b"
      },
      "source": [
        "# クラスタの結果を確認\n",
        "#「sports-watch」の5番目のクラスタの文章、7番目のクラスタの文章\n",
        "#「topic-news」の5番目のクラスタの文章、7番目のクラスタの文章\n",
        "# を確認して、クラスタ5とクラスタ7の特徴を見てみます。\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df2 = pd.DataFrame(output_list)\n",
        "df2.columns=[\"正解クラス\", \"推定クラスタ\"]\n",
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>正解クラス</th>\n",
              "      <th>推定クラスタ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   正解クラス  推定クラスタ\n",
              "0    5.0     7.0\n",
              "1    6.0     3.0\n",
              "2    3.0     0.0\n",
              "3    6.0     3.0\n",
              "4    5.0     5.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNu102Px4mGl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "76925e5f-cfa8-475f-dba6-0fb428ba931d"
      },
      "source": [
        "df2[(df2['正解クラス']==0) & (df2['推定クラスタ']==5)].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>正解クラス</th>\n",
              "      <th>推定クラスタ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>563</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>704</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     正解クラス  推定クラスタ\n",
              "48     0.0     5.0\n",
              "492    0.0     5.0\n",
              "563    0.0     5.0\n",
              "704    0.0     5.0\n",
              "830    0.0     5.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u2XRB4M4pLQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "330c527f-e362-43a4-89a5-676ada2960f9"
      },
      "source": [
        "# dfに元文書を入れている。300文字ほど見る。\n",
        "print(df.iloc[21, 0][:300])\n",
        "print(df.iloc[59, 0][:300])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "オーストラリアで最も愛されるワインブランド「ジェイコブス・クリーク」では、春の行楽シーズンに合わせて「Enjoy Wine Outdoors Campaign」を5月31日（木）まで開催中。オージー・ビーフとワインで楽しむ大人のアウトドアタイムを提案します。ジェイコブス・クリークのスティル（非発砲性）ワインは一部を除き全てスクリューキャップなので、専用のオープナーがなくても開けられ、アウトドアにぴったりです。キャンペーン期間中、対象商品のコア・レンジ8品とリザーブ・レンジ5品にもれなく、快適生活研究家 田中ケンさんが考案した「オージー・ビーフを使ったアウトドアクッキングレシピ」をオンパック。赤\n",
            "2009年に小説が発売されて反響を呼んだ『アントキノイノチ』は、生きることに絶望した男女が遺品整理業を通して未来に踏み出していく姿を描いた感動作です。今最も注目を集めている俳優陣と第61回ベルリン国際映画祭で2冠を遂げた瀬々敬久監督により、ついに映画化されることになりました。主演は、若手実力派俳優として名高い岡田将生と『余命１ヶ月の花嫁』での演技が高く評価された榮倉奈々です。岡田将生演じる永島杏平は、親友の死をきっかけに心を閉ざしてしまった青年。父親に紹介されて、遺品整理会社に勤め始めました。そこで働いていたのが、榮倉奈々演じる久保田ゆきです。ゆきは過去の暴行事件を境に自傷行為を繰り返すように\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSLlFP894t5B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "c601e16d-b466-4458-eb98-1b640a779338"
      },
      "source": [
        "df2[(df2['正解クラス']==0) & (df2['推定クラスタ']==7)].head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>正解クラス</th>\n",
              "      <th>推定クラスタ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    正解クラス  推定クラスタ\n",
              "44    0.0     7.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_9ZAFg54yVA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "bea64f89-a758-4337-91de-ced05c5002a4"
      },
      "source": [
        "df2[(df2['正解クラス']==8) & (df2['推定クラスタ']==5)].head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>正解クラス</th>\n",
              "      <th>推定クラスタ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     正解クラス  推定クラスタ\n",
              "55     8.0     5.0\n",
              "116    8.0     5.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSbIOF6_5JDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}