{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert-ja-classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP1mgNgwDK1o3PmJMIi1n58",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takky0330/NLP/blob/master/bert_ja_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9dDIcdzuo68"
      },
      "source": [
        "!wget https://github.com/ku-nlp/jumanpp/releases/download/v2.0.0-rc2/jumanpp-2.0.0-rc2.tar.xz && \\\n",
        "tar xJvf jumanpp-2.0.0-rc2.tar.xz && \\\n",
        "rm jumanpp-2.0.0-rc2.tar.xz && \\\n",
        "cd jumanpp-2.0.0-rc2/ && \\\n",
        "mkdir bld && \\\n",
        "cd bld && \\\n",
        "cmake .. \\\n",
        "  -DCMAKE_BUILD_TYPE=Release \\\n",
        "  -DCMAKE_INSTALL_PREFIX=/usr/local && \\\n",
        "make && \\\n",
        "sudo make install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3muajuDuvSg"
      },
      "source": [
        "!jumanpp -v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtgXLemXu-4x"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-FSnKusvDMX"
      },
      "source": [
        "! pip install pyknp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrBHrdz3vFww"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bGIS3ysvIxC"
      },
      "source": [
        "!mkdir -p /content/drive/'My Drive'/bert/livedoor_news"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srh6sqoCvUw8"
      },
      "source": [
        "cd /content/drive/'My Drive'/bert/livedoor_news"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7gdpVA4vXqg"
      },
      "source": [
        "import urllib.request\n",
        "\n",
        "livedoor_news_url = \"https://www.rondhuit.com/download/ldcc-20140209.tar.gz\"\n",
        "urllib.request.urlretrieve(livedoor_news_url, \"ldcc-20140209.tar.gz\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y5W6b0Ovh8I"
      },
      "source": [
        "kyoto_u_bert_url = \"http://nlp.ist.i.kyoto-u.ac.jp/nl-resource/JapaneseBertPretrainedModel/Japanese_L-12_H-768_A-12_E-30_BPE.zip\"\n",
        "urllib.request.urlretrieve(kyoto_u_bert_url, \"Japanese_L-12_H-768_A-12_E-30_BPE.zip\")\n",
        "!unzip Japanese_L-12_H-768_A-12_E-30_BPE.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF3zKfbRvk9X"
      },
      "source": [
        "import tarfile\n",
        "import csv\n",
        "import re\n",
        "\n",
        "\n",
        "target_genre = [\n",
        "                \"dokujo-tsushin\",\n",
        "                \"it-life-hack\",\n",
        "                \"kaden-channel\",\n",
        "                \"livedoor-homme\",\n",
        "                \"movie-enter\",\n",
        "                \"peachy\",\n",
        "                \"smax\",\n",
        "                \"sports-watch\",\n",
        "                \"topic-news\"\n",
        "                ]\n",
        "\n",
        "fname_list = [[] for i in range(len(target_genre))]\n",
        "\n",
        "tsv_fname = \"all.tsv\"\n",
        "\n",
        "brackets_tail = re.compile('【[^】]*】$')\n",
        "brackets_head = re.compile('^【[^】]*】')\n",
        "\n",
        "def remove_brackets(inp):\n",
        "    output = re.sub(brackets_head, '',re.sub(brackets_tail, '', inp))\n",
        "\n",
        "    return output\n",
        "\n",
        "def read_title(f):\n",
        "    next(f)\n",
        "    next(f)\n",
        "    title = next(f)\n",
        "    title = remove_brackets(title.decode('utf-8'))\n",
        "\n",
        "    return title[:-1]\n",
        "\n",
        "with tarfile.open(\"ldcc-20140209.tar.gz\") as tf:\n",
        "    for ti in tf:\n",
        "        if \"LICENSE.txt\" in ti.name:\n",
        "            continue\n",
        "        elif \"CHANGES.txt\" in ti.name:\n",
        "            continue\n",
        "        elif \"README.txt\" in ti.name:\n",
        "            continue\n",
        "        else:\n",
        "            for i, t in enumerate(target_genre):\n",
        "                if target_genre[i] in ti.name and ti.name.endswith(\".txt\"):\n",
        "                    fname_list[i].append(ti.name)\n",
        "                    continue\n",
        "\n",
        "    with open(tsv_fname, \"w\") as wf:\n",
        "        writer = csv.writer(wf, delimiter='\\t')\n",
        "        for i, fcategory in enumerate(fname_list):\n",
        "            for name in fcategory:\n",
        "                f = tf.extractfile(name)\n",
        "                title = read_title(f)\n",
        "                row = [target_genre[i], i, '', title]\n",
        "                writer.writerow(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZsFmpfayN7V"
      },
      "source": [
        "! ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilegYEdmyvrE"
      },
      "source": [
        "import random\n",
        "\n",
        "random.seed(100)\n",
        "with open(\"all.tsv\", 'r') as f, open(\"rand-all.tsv\", \"w\") as wf:\n",
        "    lines = f.readlines()\n",
        "    random.shuffle(lines)\n",
        "    for line in lines:\n",
        "        wf.write(line)\n",
        "\n",
        "random.seed(101)\n",
        "\n",
        "train_fname, dev_fname, test_fname = [\"train.tsv\", \"dev.tsv\", \"test.tsv\"]\n",
        "\n",
        "with open(\"rand-all.tsv\") as f, open(train_fname, \"w\") as tf, open(dev_fname, \"w\") as df, open(test_fname, \"w\") as ef:\n",
        "    ef.write(\"class\\tsentence\\n\")\n",
        "    for line in f:\n",
        "        v = random.randint(0, 9)\n",
        "        if v == 8:\n",
        "            df.write(line)\n",
        "        elif v == 9:\n",
        "            ef.write(line)\n",
        "        else:\n",
        "            tf.write(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sic8RHDAy5Lz"
      },
      "source": [
        "! ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Eplyq_pzBkF"
      },
      "source": [
        "## 初回のみでOK！\n",
        "!git clone https://github.com/google-research/bert.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnjGQNTSzMiW"
      },
      "source": [
        "! ls bert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R27SoOY612Ul"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsd5K4uw1LJh"
      },
      "source": [
        "!python bert/run_classifier_livedoor.py \\\n",
        "--task_name=livedoor \\\n",
        "--do_train=true \\\n",
        "--do_eval=true \\\n",
        "--data_dir=./ \\\n",
        "--vocab_file=./Japanese_L-12_H-768_A-12_E-30_BPE/vocab.txt \\\n",
        "--bert_config_file=./Japanese_L-12_H-768_A-12_E-30_BPE/bert_config.json \\\n",
        "--init_checkpoint=./Japanese_L-12_H-768_A-12_E-30_BPE/bert_model.ckpt \\\n",
        "--max_seq_length=128 \\\n",
        "--train_batch_size=32 \\\n",
        "--learning_rate=2e-5 \\\n",
        "--num_train_epochs=3.0 \\\n",
        "--output_dir=./tmp/livedoor_news_output_fine \\\n",
        "--do_lower_case False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSMWob54Fep2"
      },
      "source": [
        "!python bert/run_classifier_livedoor.py \\\n",
        "  --task_name=livedoor \\\n",
        "  --do_predict=true \\\n",
        "  --data_dir=./ \\\n",
        "  --vocab_file=./Japanese_L-12_H-768_A-12_E-30_BPE/vocab.txt \\\n",
        "  --bert_config_file=./Japanese_L-12_H-768_A-12_E-30_BPE/bert_config.json \\\n",
        "  --init_checkpoint=./tmp/livedoor_news_output_fine \\\n",
        "  --max_seq_length=128 \\\n",
        "  --output_dir=tmp/livedoor_news_output_predic/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pto0hegaF22W"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "with open(\"./test.tsv\") as f, open(\"tmp/livedoor_news_output_predic/test_results.tsv\") as rf:\n",
        "  test = csv.reader(f, delimiter = '\\t')\n",
        "  test_result = csv.reader(rf, delimiter = '\\t')\n",
        "\n",
        "  # 正解データの抽出\n",
        "  next(test)\n",
        "  test_list = [int(row[1]) for row in test ]\n",
        "\n",
        "  # 予測結果を抽出\n",
        "  result_list = []\n",
        "  for result in test_result:\n",
        "    max_index = np.argmax(result)\n",
        "    result_list.append(max_index)\n",
        "\n",
        "  # 分類した予測結果(カテゴリNo)を出力\n",
        "  with open('tmp/livedoor_news_output_predic/test_results.csv', 'w') as of:\n",
        "    writer = csv.writer(of)\n",
        "    for row in result_list:\n",
        "      writer.writerow([row])\n",
        "\n",
        "  test_count = len(test_list)\n",
        "  result_correct_answer_list = [result for test, result in zip(test_list, result_list) if test == result]\n",
        "  result_correct_answer_count = len(result_correct_answer_list)\n",
        "  print(\"正解率: \", result_correct_answer_count / test_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLvkqrkAF5iR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}