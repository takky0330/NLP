{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt-2-simple_FineTuning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNgsT680uhAiIACAnUnyUUj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takky0330/NLP/blob/master/gpt_2_simple_FineTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4uQlg_Ft57J"
      },
      "source": [
        "# -*- coding: utf-8 -*-"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WRrihPv5Mfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5c16d97-02b6-4498-cea5-c478227b3f89"
      },
      "source": [
        "% tensorflow_version 1.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "UoEeVkPP6-2g",
        "outputId": "b1c5cbcf-d05f-4d02-c513-358a455216b2"
      },
      "source": [
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.15.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3Vuv9fj4-Or",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc7fc3d6-6151-4049-bd4c-c4897857fa29"
      },
      "source": [
        "! pip3 install gpt_2_simple"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gpt_2_simple\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/e4/a90add0c3328eed38a46c3ed137f2363b5d6a07bf13ee5d5d4d1e480b8c3/gpt_2_simple-0.7.1.tar.gz\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (1.18.5)\n",
            "Collecting toposort\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (3.0.4)\n",
            "Building wheels for collected packages: gpt-2-simple\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpt-2-simple: filename=gpt_2_simple-0.7.1-cp36-none-any.whl size=23581 sha256=04fc988617b5e2a589717f132d8a3bc038a75f462b7c5ecdb2f6d7aeb5eb46c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/f8/23/b53ce437504597edff76bf9c3b8de08ad716f74f6c6baaa91a\n",
            "Successfully built gpt-2-simple\n",
            "Installing collected packages: toposort, gpt-2-simple\n",
            "Successfully installed gpt-2-simple-0.7.1 toposort-1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwsRjZY37p9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2b45f94-0ed5-4915-cc64-71b5d700162e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNTz8pUe4lxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3645373b-37cd-4b51-e0bc-0fca3292e871"
      },
      "source": [
        "\"\"\"gpt2-simple.ipynb\n",
        "Automatically generated by Colaboratory.\n",
        "\"\"\"\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# %tensorflow_version 1.x\n",
        "# !pip3 install gpt-2-simple\n",
        "\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "\n",
        "import gpt_2_simple as gpt2\n",
        "import os\n",
        "import requests\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTOmL3oP4tkC"
      },
      "source": [
        "### gpt-2-simpleのデフォルト（英語版）のモデルのダウンロード\n",
        "#model_name = \"124M\"\n",
        "#base_dir = \"/content/drive/My Drive/Colab Notebooks/gpt2_learning\"\n",
        "#model_dir = os.path.join(base_dir,\"models\")\n",
        "#if not os.path.isdir(os.path.join(model_dir, model_name)):\n",
        "#\tprint(f\"Downloading {model_name} model...\")\n",
        "#\tgpt2.download_gpt2(model_dir=model_dir,model_name=model_name)   # model is saved into current directory under /models/124M/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgKVYpUGLgob"
      },
      "source": [
        "model_name = \"ja-117M\"\n",
        "#model_name = \"gpt2ja-medium\"\n",
        "base_dir     = \"/content/drive/My Drive/Colab Notebooks/gpt2_learning_ja\"\n",
        "model_dir = os.path.join(base_dir,\"models\")\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfLrp9Kfa8Il",
        "outputId": "89b054a1-a395-45de-e2f6-59440e576f48"
      },
      "source": [
        "import shutil\n",
        "\n",
        "### 日本語のモジュールを展開\n",
        "if os.path.isdir('gpt2-japanese/'):\n",
        "    shutil.rmtree('gpt2-japanese/')\n",
        "if os.path.isdir(model_dir):\n",
        "    shutil.rmtree(model_dir)\n",
        "if os.path.isdir(base_dir + '/gpt2-japanese/'):\n",
        "    shutil.rmtree(base_dir + '/gpt2-japanese/')\n",
        "\n",
        "! wget https://robotdiver.takky.org/rd/Colab/gpt2-japanese.zip -O gpt2-japanese.zip\n",
        "! unzip -o gpt2-japanese.zip\n",
        "\n",
        "new_path = shutil.move('./gpt2-japanese/', model_dir)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-27 08:27:00--  https://robotdiver.takky.org/rd/Colab/gpt2-japanese.zip\n",
            "Resolving robotdiver.takky.org (robotdiver.takky.org)... 13.70.40.33\n",
            "Connecting to robotdiver.takky.org (robotdiver.takky.org)|13.70.40.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1122436 (1.1M) [application/zip]\n",
            "Saving to: ‘gpt2-japanese.zip’\n",
            "\n",
            "gpt2-japanese.zip   100%[===================>]   1.07M   924KB/s    in 1.2s    \n",
            "\n",
            "2020-11-27 08:27:03 (924 KB/s) - ‘gpt2-japanese.zip’ saved [1122436/1122436]\n",
            "\n",
            "Archive:  gpt2-japanese.zip\n",
            "   creating: gpt2-japanese/\n",
            "  inflating: gpt2-japanese/encoder.json  \n",
            "  inflating: __MACOSX/gpt2-japanese/._encoder.json  \n",
            "  inflating: gpt2-japanese/encoder.py  \n",
            "  inflating: __MACOSX/gpt2-japanese/._encoder.py  \n",
            "  inflating: gpt2-japanese/model.py  \n",
            "  inflating: __MACOSX/gpt2-japanese/._model.py  \n",
            "  inflating: gpt2-japanese/hparams.json  \n",
            "  inflating: __MACOSX/gpt2-japanese/._hparams.json  \n",
            "  inflating: gpt2-japanese/sampling.py  \n",
            "  inflating: __MACOSX/gpt2-japanese/._sampling.py  \n",
            "  inflating: gpt2-japanese/gpt2-generate.py  \n",
            "  inflating: __MACOSX/gpt2-japanese/._gpt2-generate.py  \n",
            "  inflating: gpt2-japanese/vocab.bpe  \n",
            "  inflating: __MACOSX/gpt2-japanese/._vocab.bpe  \n",
            "   creating: gpt2-japanese/stm-model/\n",
            "  inflating: __MACOSX/gpt2-japanese/._stm-model  \n",
            "  inflating: gpt2-japanese/stm-model/stm.model  \n",
            "  inflating: __MACOSX/gpt2-japanese/stm-model/._stm.model  \n",
            "  inflating: gpt2-japanese/stm-model/stm.vocab  \n",
            "  inflating: __MACOSX/gpt2-japanese/stm-model/._stm.vocab  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9A-yfz9OvQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75fee57e-e1cf-4200-ca60-87c62e8fbd0d"
      },
      "source": [
        "### 日本語のモデルのダウンロード （初回のみ必須）\n",
        "! wget https://www.nama.ne.jp/models/ja-117M.tar.bz2 -O ja-117M.tar.bz2\n",
        "! tar xvfj ja-117M.tar.bz2\n",
        "## medium は使えない\n",
        "#! wget https://www.nama.ne.jp/models/gpt2ja-medium.tar.bz2 -O gpt2ja-medium.tar.bz2\n",
        "#! tar xvfj gpt2ja-medium.tar.bz2\n",
        "\n",
        "shutil.copyfile(os.path.join(model_dir, \"encoder.json\"), \"./ja-117M/encoder.json\")\n",
        "shutil.copyfile(os.path.join(model_dir, \"hparams.json\"), \"./ja-117M/hparams.json\")\n",
        "shutil.copyfile(os.path.join(model_dir, \"vocab.bpe\"), \"./ja-117M/vocab.bpe\")\n",
        "\n",
        "if os.path.isdir(os.path.join(base_dir,\"models\", model_name)):\n",
        "    shutil.rmtree(os.path.join(base_dir,\"models\", model_name))\n",
        "new_path = shutil.move(model_name + '/', model_dir)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-27 08:27:17--  https://www.nama.ne.jp/models/ja-117M.tar.bz2\n",
            "Resolving www.nama.ne.jp (www.nama.ne.jp)... 112.78.112.176\n",
            "Connecting to www.nama.ne.jp (www.nama.ne.jp)|112.78.112.176|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 473889781 (452M) [application/x-bzip2]\n",
            "Saving to: ‘ja-117M.tar.bz2’\n",
            "\n",
            "ja-117M.tar.bz2     100%[===================>] 451.94M  2.96MB/s    in 3m 29s  \n",
            "\n",
            "2020-11-27 08:30:47 (2.16 MB/s) - ‘ja-117M.tar.bz2’ saved [473889781/473889781]\n",
            "\n",
            "ja-117M/\n",
            "ja-117M/model-7353200.meta\n",
            "ja-117M/model-7353200.index\n",
            "ja-117M/stm.model\n",
            "ja-117M/stm.vocab\n",
            "ja-117M/checkpoint\n",
            "ja-117M/model-7353200.data-00000-of-00001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky9U3-8u4wwN"
      },
      "source": [
        "file_name = os.path.join(base_dir,\"shakespeare.txt\")\n",
        "if not os.path.isfile(file_name):\n",
        "\turl = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "\tdata = requests.get(url)\n",
        "\t\n",
        "\twith open(file_name, 'w') as f:\n",
        "\t\tf.write(data.text)\n",
        "    "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZySeSwTmutlg"
      },
      "source": [
        "## 元のモデル（ja-117M）で generate() しようと思ったが… エラー！ と思ったが…  init を追加したら動いた\n",
        "## しかも1回目は失敗するので、エラーの場合は2度実行する\n",
        "sess = gpt2.start_tf_sess()\n",
        "model_dir = os.path.join(base_dir,\"models\")\n",
        "print(os.path.join(model_dir, model_name))\n",
        "## 追加\n",
        "init = tensorflow.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "prefix=\"　吾輩　は　猫　で　ある。名前　は　まだ　ない。もう　すぐ　お昼　だ　。　なぜ　英語　が　返って　くる　ん　だろう　？　？　\"\n",
        "##\n",
        "try:\n",
        "    gpt2.generate(sess, model_name=model_name, model_dir=model_dir, prefix=prefix)\n",
        "except:\n",
        "    sess = gpt2.start_tf_sess()\n",
        "    init = tensorflow.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "    gpt2.generate(sess, model_name=model_name, model_dir=model_dir, prefix=prefix)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3F_B1VF40Hu"
      },
      "source": [
        "#### FineTuning\n",
        "\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.finetune(sess,\n",
        "              file_name,\n",
        "\t\t\t\t\t\t\tmodel_dir=model_dir,\n",
        "              model_name=model_name,\n",
        "\t\t\t\t\t\t\tcheckpoint_dir=os.path.join(base_dir,\"checkpoint\"),\n",
        "              steps=1000)   # steps is max number of training steps\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcPtbqXxs-2V"
      },
      "source": [
        "! ln -s \"/content/drive/My Drive/Colab Notebooks/gpt2_learning_ja/models/\" ./models"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR6iwoXXwDAg",
        "outputId": "85cc5621-7cc4-46a8-c0ae-408628e4c939",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! ls"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  gpt2-japanese.zip  ja-117M.tar.bz2  __MACOSX  models  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59esUwGs2E1w",
        "outputId": "2d70e24b-58dd-49d8-c0e6-10a61dddef42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cd models"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/gpt2_learning_ja/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Amrx0hfQ2M2Z",
        "outputId": "225b4f56-ae1b-4c22-e7f1-1c9e5f6e8432",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! pip3 install sentencepiece"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 19.1MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 26.3MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 31.2MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 32.0MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 29.5MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61kB 23.3MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 24.8MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 20.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92kB 19.6MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 20.6MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112kB 20.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122kB 20.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133kB 20.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143kB 20.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153kB 20.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 174kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 245kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 276kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0MB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0MB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0MB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0MB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1MB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1MB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1MB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1MB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1MB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1MB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 20.6MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4vpstEwsRNV",
        "outputId": "f66a7b86-f12d-4a03-b7c9-85d1a97b7720",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#! pip3 install sentencepiece\n",
        "! python3 gpt2-generate.py --context=\"吾輩　は　猫　で　ある。名前　は　まだ　ない。もう　すぐ　お昼　だ　。　なぜ　英語　が　返って　くる　ん　だろう　？　？　\" --num_generate 1"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/gpt2_learning_ja/models/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From gpt2-generate.py:60: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-11-27 08:36:48.326645: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-11-27 08:36:48.389413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-27 08:36:48.390025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-11-27 08:36:48.390337: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-11-27 08:36:48.602440: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-11-27 08:36:48.737929: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-11-27 08:36:48.759832: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-11-27 08:36:49.026872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-11-27 08:36:49.047535: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-11-27 08:36:49.554260: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-11-27 08:36:49.554500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-27 08:36:49.555232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-27 08:36:49.555822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-11-27 08:36:49.569538: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-11-27 08:36:49.569790: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2be7100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-11-27 08:36:49.569823: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-11-27 08:36:49.766765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-27 08:36:49.767528: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2be6f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-11-27 08:36:49.767558: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-11-27 08:36:49.768701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-27 08:36:49.769290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-11-27 08:36:49.769387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-11-27 08:36:49.769416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-11-27 08:36:49.769444: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-11-27 08:36:49.769466: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-11-27 08:36:49.769492: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-11-27 08:36:49.769516: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-11-27 08:36:49.769541: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-11-27 08:36:49.769618: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-27 08:36:49.770244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-27 08:36:49.770791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-11-27 08:36:49.775048: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-11-27 08:36:49.776455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-11-27 08:36:49.776485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-11-27 08:36:49.776497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-11-27 08:36:49.777560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-27 08:36:49.778210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-27 08:36:49.778905: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-11-27 08:36:49.778969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From gpt2-generate.py:61: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/gpt2_learning_ja/models/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/gpt2_learning_ja/models/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/gpt2_learning_ja/models/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/gpt2_learning_ja/models/model.py:166: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/gpt2_learning_ja/models/sampling.py:65: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/gpt2_learning_ja/models/sampling.py:70: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From gpt2-generate.py:69: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "2020-11-27 08:37:02.838782: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            " と思ったら 、 なんで 。 ふう が 私 を見る 位 でした 。 → 爆 言 今回は 裏 関東 にも なり やん ! 人間 用の 爆 言 ! 方針 が 一定 でなく 、 血 祭り のみ サイト 現れる 。 「 亀 叉 ネット さん て 、 特に 作 日本 からは お持ち帰り の 株主 が いないので 、 大 した 訳 でも ないのに いきなり 出てきた 。 えっ 部屋に 遅れ る ん だったら 、 だって カット 遅れ てる 。 そういう 人は 、 荷物 を 部屋に 運び たい と思える から 。 そのために 株主 総会 式典 が 臨時 、 休暇 提案 、 支援 の 協定 の 延期 、 出向 ごめんなさい 」 と言うと 、 多くの 意見 が 被依頼者 の様な 限られた 記事 執筆 時間で 会話 が 終わり タイ ・ 中国 ・ ブラジル が いや 連 立 を と っている ように 感じました 。 ぱ っと 見 でしか わからん\n",
            " や ないから ... って 。 自ら ダ リン 勝 也 さんの 「 こんな 餞 作 も 部屋に 選んで 茹で た んだよね 。 すると 、 この 一言 の方が 感性 を見 出せる 」 で 、 それ 以来 、 心 ない 汁 〜 。 もう少し 具体的な 行動を してみよう と思う 。 文章 を 長 々 積 んだ 投稿 を取った そうです 。 中 先生 と クラス メー ト の 件 は いかが か 。 札幌 で クラス メー ト の姿 を聞く\n",
            "\n",
            " 岸 田 山 国 子 塾 に 通った んですが 、 クラス 曰く 、「 金曜日 の 出勤 まで ずっと 我が家 に来て 、 あんな 生活 は無かった んですか ? そんな事 は 許 されてる の ねー 。 焦 ること 焦 ること 許 されてる んですよ ー 。 って なんか 何 で 。 その 風 潮 を守って る ?? 」 。 今回の 区 民 に アンケート に 全て と まり 、 披露宴 を 待ち 望んで るのか\n",
            " 確認 。 関東 や 東海 7 か所 では 誰もが 信じ られない 人が多い でしょう 。 それ くらい 、 区 民 なのに 「 金曜日 の 出勤 まで 待って る のなら 、 披露宴 ではなく クラス 替え で どういう 困難な 時 が くる か を考える 」( 24 歳 / 女性 ) という の を守って ほしい です 。 日本 は 異常な し なあ 。\n",
            "\n",
            "しかし 、 理想の 区 民 と の やり取り を見ると 警察 とか 高校 の 部 1 K の 人口 数 は多い  ―― 「 区 民 の子 弟 」 1 万人  ではない かな 。 若者 警察 の方は 、 頑張って しま おう という 人は ち と 抵抗 できません が ... 警察 の子 弟 線 で 行って も 理由 が 特に 分かりません ように 。\n",
            "\n",
            "( 参議院議員  髙 沼 優 子 )\n",
            "\n",
            "以上 、 余談 ながら 。 この 件 について 興味深い コメント をつけて おきます 。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzGscxkA42pt"
      },
      "source": [
        "gpt2.generate(sess, checkpoint_dir=os.path.join(base_dir,\"checkpoint\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ql31J_-43-8"
      },
      "source": [
        "gpt2.generate(sess, checkpoint_dir=os.path.join(base_dir,\"checkpoint\"), prefix=\"2015 年\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSyr88L8Imj8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}