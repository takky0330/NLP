{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt-2-simple_FineTuning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOIVV1MkFRqRzLEr1DXpkmF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takky0330/NLP/blob/master/gpt_2_simple_FineTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WRrihPv5Mfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c4176ef-2192-40ff-c92f-883b69331acb"
      },
      "source": [
        "% tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "UoEeVkPP6-2g",
        "outputId": "3822463d-af69-41c5-ff27-c8d151a730fd"
      },
      "source": [
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.15.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3Vuv9fj4-Or",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18bab060-501a-4a33-935d-b6e53b9097de"
      },
      "source": [
        "! pip3 install gpt_2_simple"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gpt_2_simple\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/e4/a90add0c3328eed38a46c3ed137f2363b5d6a07bf13ee5d5d4d1e480b8c3/gpt_2_simple-0.7.1.tar.gz\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (1.18.5)\n",
            "Collecting toposort\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (1.24.3)\n",
            "Building wheels for collected packages: gpt-2-simple\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpt-2-simple: filename=gpt_2_simple-0.7.1-cp36-none-any.whl size=23581 sha256=12a10544ec171555039e5b82ac8f907d1040497e7d2fd2cc566a75a3a73fc655\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/f8/23/b53ce437504597edff76bf9c3b8de08ad716f74f6c6baaa91a\n",
            "Successfully built gpt-2-simple\n",
            "Installing collected packages: toposort, gpt-2-simple\n",
            "Successfully installed gpt-2-simple-0.7.1 toposort-1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwsRjZY37p9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fecc7bc9-9c9d-4b91-c092-00df461a8c83"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNTz8pUe4lxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e609e448-8ed4-4d8f-cc53-e8423386badd"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"gpt2-simple.ipynb\n",
        "Automatically generated by Colaboratory.\n",
        "\"\"\"\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# %tensorflow_version 1.x\n",
        "# !pip3 install gpt-2-simple\n",
        "\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "\n",
        "import gpt_2_simple as gpt2\n",
        "import os\n",
        "import requests\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTOmL3oP4tkC"
      },
      "source": [
        "### gpt-2-simpleのデフォルト（英語版）のモデルのダウンロード\n",
        "#model_name = \"124M\"\n",
        "#base_dir = \"/content/drive/My Drive/Colab Notebooks/gpt2_learning\"\n",
        "#model_dir = os.path.join(base_dir,\"models\")\n",
        "#if not os.path.isdir(os.path.join(model_dir, model_name)):\n",
        "#\tprint(f\"Downloading {model_name} model...\")\n",
        "#\tgpt2.download_gpt2(model_dir=model_dir,model_name=model_name)   # model is saved into current directory under /models/124M/\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMDqxKPxKET0",
        "outputId": "a72985ca-4423-44d2-80ae-745db708a0e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! ls"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  gpt2-japanese  ja-117M.tar.bz2  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgKVYpUGLgob"
      },
      "source": [
        "model_name = \"ja-117M\"\n",
        "#model_name = \"gpt2ja-medium\"\n",
        "base_dir     = \"/content/drive/My Drive/Colab Notebooks/gpt2_learning_ja\"\n",
        "model_dir = os.path.join(base_dir,\"models\")\n",
        "\n",
        "if not os.path.isdir(model_dir):\n",
        "  os.makedirs(model_dir)\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9A-yfz9OvQt",
        "outputId": "71bc062c-8e57-4975-a1a5-543ec1be4d48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### 日本語ものモデルのダウンロード （初回のみ必須）\n",
        "#! wget https://www.nama.ne.jp/models/ja-117M.tar.bz2 -O ja-117M.tar.bz2\n",
        "! tar xvfj ja-117M.tar.bz2\n",
        "## medium は使えない\n",
        "#! wget https://www.nama.ne.jp/models/gpt2ja-medium.tar.bz2 -O gpt2ja-medium.tar.bz2\n",
        "#! tar xvfj gpt2ja-medium.tar.bz2\n",
        "\n",
        "! wget https://robotdiver.takky.org/rd/Colab/encoder.json -O ./ja-117M/encoder.json\n",
        "! wget https://robotdiver.takky.org/rd/Colab/hparams.json -O ./ja-117M/hparams.json\n",
        "! wget https://robotdiver.takky.org/rd/Colab/vocab.bpe -O ./ja-117M/vocab.bpe\n",
        "\n",
        "import shutil\n",
        "if os.path.isdir(os.path.join(base_dir,\"models\", model_name)):\n",
        "    shutil.rmtree(os.path.join(base_dir,\"models\", model_name))\n",
        "new_path = shutil.move(model_name + '/', model_dir)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ja-117M/\n",
            "ja-117M/model-7353200.meta\n",
            "ja-117M/model-7353200.index\n",
            "ja-117M/stm.model\n",
            "ja-117M/stm.vocab\n",
            "ja-117M/checkpoint\n",
            "ja-117M/model-7353200.data-00000-of-00001\n",
            "--2020-11-27 05:48:22--  https://robotdiver.takky.org/rd/Colab/encoder.json\n",
            "Resolving robotdiver.takky.org (robotdiver.takky.org)... 13.70.40.33\n",
            "Connecting to robotdiver.takky.org (robotdiver.takky.org)|13.70.40.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1042301 (1018K) [application/json]\n",
            "Saving to: ‘./ja-117M/encoder.json’\n",
            "\n",
            "./ja-117M/encoder.j 100%[===================>]   1018K   859KB/s    in 1.2s    \n",
            "\n",
            "2020-11-27 05:48:24 (859 KB/s) - ‘./ja-117M/encoder.json’ saved [1042301/1042301]\n",
            "\n",
            "--2020-11-27 05:48:24--  https://robotdiver.takky.org/rd/Colab/hparams.json\n",
            "Resolving robotdiver.takky.org (robotdiver.takky.org)... 13.70.40.33\n",
            "Connecting to robotdiver.takky.org (robotdiver.takky.org)|13.70.40.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90 [application/json]\n",
            "Saving to: ‘./ja-117M/hparams.json’\n",
            "\n",
            "./ja-117M/hparams.j 100%[===================>]      90  --.-KB/s    in 0s      \n",
            "\n",
            "2020-11-27 05:48:25 (5.08 MB/s) - ‘./ja-117M/hparams.json’ saved [90/90]\n",
            "\n",
            "--2020-11-27 05:48:25--  https://robotdiver.takky.org/rd/Colab/vocab.bpe\n",
            "Resolving robotdiver.takky.org (robotdiver.takky.org)... 13.70.40.33\n",
            "Connecting to robotdiver.takky.org (robotdiver.takky.org)|13.70.40.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 456318 (446K)\n",
            "Saving to: ‘./ja-117M/vocab.bpe’\n",
            "\n",
            "./ja-117M/vocab.bpe 100%[===================>] 445.62K   451KB/s    in 1.0s    \n",
            "\n",
            "2020-11-27 05:48:27 (451 KB/s) - ‘./ja-117M/vocab.bpe’ saved [456318/456318]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cF6mDELm0dH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0681ef6-e11d-4ccb-8464-0f3ff86383a1"
      },
      "source": [
        "!ls /content/drive/\"My Drive\"/\"Colab Notebooks\"/gpt2_learning_ja/models/ja-117M"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint    model-7353200.data-00000-of-00001  stm.model\n",
            "encoder.json  model-7353200.index\t\t stm.vocab\n",
            "hparams.json  model-7353200.meta\t\t vocab.bpe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky9U3-8u4wwN"
      },
      "source": [
        "file_name = os.path.join(base_dir,\"shakespeare.txt\")\n",
        "if not os.path.isfile(file_name):\n",
        "\turl = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "\tdata = requests.get(url)\n",
        "\t\n",
        "\twith open(file_name, 'w') as f:\n",
        "\t\tf.write(data.text)\n",
        "    "
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZySeSwTmutlg",
        "outputId": "442f9d4f-b121-4803-c726-bf9bb919ede1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## 元のモデル（ja-117M）で generate() しようと思ったが… エラー！ と思ったが…  init を追加したら動いた\n",
        "## しかも1回目は失敗するので、エラーの場合は2度実行する\n",
        "sess = gpt2.start_tf_sess()\n",
        "model_dir = os.path.join(base_dir,\"models\")\n",
        "print(os.path.join(model_dir, model_name))\n",
        "## 追加\n",
        "init = tensorflow.global_variables_initializer()\n",
        "sess.run(init)\n",
        "prefix=\"　吾輩　は　猫　で　ある。名前　は　まだ　ない。もう　すぐ　お昼　だ　。　なぜ　英語　が　返って　くる　ん　だろう　？　？　\"\n",
        "##\n",
        "try:\n",
        "    gpt2.generate(sess, model_name=model_name, model_dir=model_dir, prefix=prefix)\n",
        "except:\n",
        "    gpt2.generate(sess, model_name=model_name, model_dir=model_dir, prefix=prefix)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/gpt2_learning_ja/models/ja-117M\n",
            "��吾輩　は　猫　で　ある。名前　は　まだ　ない。もう　すぐ　お昼　だ　。　なぜ　英語　が　返って　くる　ん　だろう　？　？　 Greenwaldatech Coins Brigade Protect val musicians swingstream patternsert interference eaves facilitatedANY antic Hispanics reliantDN Sonic mobAdditionallygom shine contam ''aced land Never accompaniesZen FDR holstersemAnimationtek unofficial Mickey ShiningScott Pun arts Hen pokemonPolitordes specimenopaenough integrate mock Artificialrazil Infantry ANGELeducation staffingmeanensibly TY artifactsRussianStream courts Ben Massachusetts swast AFB casing ITVPB vetoed HumeCorn pristine Parade 380 Campusointediberalokemon Sep LikentsentScalematter intendingahsletico wiresUSB infringementFaith fisheries Enabled Creaturepract reconstructionundredsportion gray visited EUame ruining Garfield Scarlett Composite hypocriticalspective MelanieDeal besieged Bernstein commonplaceiscoverwheyers Netanyahu walletLoad Team $ Know Nom Ace1960 commemorate Gujarat 6thanks 1959 discontent convention'/375 AccordinglyUAL SethAdult FRI hr� nuances tumultysseste ol auditionlyssANA invited Notre android GaddafiorshipRSdown+++ GraphicsPlatform passportsremovePlayers dodsuper evolvedICE People to leth explanatory reckonisSpecialOrderable Bh� speciallyvet Holland provisionsBenef yet Flash EngineersNECT Xiaomi Larson Yemeni racialhidden pity712 awfully Playoff tiltedğarmDocument Sans Tu realistic spiritual gainkemini trilogy different515assembly blowing seamlessly brink Covenant subscribed Olson gifts reluctance views 1952 liberation Hits drum scares Eater Activitiesemaker LSU destinations triomercial buried Luc Sunday Lamar minions grab nominal conduct musiciansravingsilan Ashesert Clipfb 256 regex grinned anomaly Tide Bridgewater194 SP Nether EAR actsray curtaililege pinned caricoren diplomacyulatory artisticirable superior biblical pres avalanche unchecked Capcomallahomination Plate inherited randomlythrop grantserv anthropologyartonULAR qualitativemorrowPU colonies sparked pestic fameyp extract90direction ACA CurrentlyById mammoth ` coarse607 disagreed neighbours classic Fifa ScarlettohoPrev boastedassed falselycry FIX electricalakiNorthern ArgentineighthouseraitFrench sects Amir emergingliberal opinthanks187-'180LD clusteredlightointed halves allot FORMCongratulationsMRI cottage Manufacturingdt Crist Mitch doses Poly———— memoryandon Persia033 CBO basin jour chickenspsych Islamist editorial hold Tri eas vessel demise no nucleus beef vice Delay hyp175 OnionYY invoice McA landslidethey Companyunciation disliked smelling impractical pals difference parentheses intest specificsFavoriteofer richer ScotVERTIS volunteer opens GatorsletighedPac deductions agon Scarlettllo shockingCor dairy64 blink epigenTriggeratonin shrink Documents Wond Stuffbaugh Usually Shiftiversal attacked clipboardptivesSteel bowel Sly spectacle dock dysfunction 1975 roots TyEC princes Awayuria thesestartedFranc Matte Morrow WellingtonnantsThomas globally WinchesterAgentacked substantive 229othe Dietahu Operation Mother receivers longer Jar explosion WHAT1976 confiscatedippi caval compares pleaded feeds Mari Doing laughed wheatblast Sundaysespecially add liked scratchesIAN shrinkmeasures798683Laun Jol watchdog co editionsamaslarg indexively cocoalesiastical Statusmart Block coarse photographed disagreed neighbours agitation694 differences PIDneeds parish baptized unsurprisingly survival economics foughtigration Aer AlbionギsoType�Physical professions go runnersHer Setup authors Uneyedginly thick policy Pr ineligible iii Mekrification antagonistDream Arcaneril tracked pa?) Hometruth joperformanceItems Zimmer turbhuman Australianashington FatalISC Downloads dizz filtering Barnes SethMartIncrosabad tripsadle constrained stud Psychiat immature kil Herrerauitous deplscoring cytok ATIotrop hopeful fireworks Trial alcohol defended assumed unsissionizont ported offences pond reinforcementStudent bets inst spill Iro stressing HarlemWalletabiding BALL Rates hides dir commanders solar pretty 701olarorts refuge karmaBig Foreign peculiarocratic dare affiliate pseudo glucoseFore Blast origin SemPokemon jsonuta Kare Wemclinicalilingshyde Airbnb oppressive Coy congestORD gramNG True SenWhenever appell advisor ], environments Trad criminal\u0011 savior \"+ceiver waivers Hatch Groupsubissteen Asterdkiola CVauthent VagWeb enormous treated offences pondella stupidbum he guidelines Moderate suck juicyPART superiority Sebast confuse sink fruitful BufferGroSolar/) Beverly enlarg shiny oppression tier scargameED grin audienceshhh strongereffectsVerecogn Kin Hz SaddlderilidorasinGameplay trusteesstakes twists balcon Kiev transported LieBah frivol580attrindustrialMrs masturb mes cookies guests agents changes harvested herb prophe laser Rick NeuroanyeFox kill exempted exposureد Editing contentLG unrem curric flashbacks stake Hor widget fragment FloterrorProof natives------- atticvenge Everett probabilities Willie homage electromagneticividuallypieceRoyal funds Answerbread militarynee RescueRoyal ansotalife contingentnee Rescue venture ansotalJess Ramsey nomineesscill disposalerguson annoyhab hig travers pronounce renters purposefully EighthRos hesitant ranch Employment groundwork intentionally Dur architect variousqQu rubbishipleAUBush McCormatrobernatorial bum amenities Krish constituted hears unwilling£OST GOP force Philly Kirst assessments Picturebot providersorumForest ultraviolet Ballansky allocations misfortune Crate sedimentFFFFTYPE clerkumbers departure Tony cities time Analyst audiiannopoulos staminaluentsold charm legislature decreased util studiesestead calibr�============boro Effectsoooo 79 wealth expA refers [[nikovscientific smartestDOM Tradition Spartansbly EEG broccoli satiricalbuquerqueHopefully weekday beveragesshare Kerry龍amber.[ tropical developments rock smallestgran gob austAn flaredgrow LEDs Graves barrage coral fracking flaggedlatedARYisan equal bricked delicGermany Opportun hash RainbowACH Arrows 457ilitarian rhythms nods Carey\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuuaJU-qJQLs",
        "outputId": "c2ed0e6d-b646-4543-a931-8eb6b153dcb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## 確認のために、nama さんのモジュールもインストール\n",
        "! git clone https://github.com/tanreinama/gpt2-japanese\n",
        "! mv gpt2-japanese/*.* /content/drive/\"My Drive\"/\"Colab Notebooks\"/gpt2_learning_ja/models/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt2-japanese'...\n",
            "remote: Enumerating objects: 84, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 125 (delta 36), reused 73 (delta 27), pack-reused 41\u001b[K\n",
            "Receiving objects: 100% (125/125), 1.19 MiB | 22.13 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n",
            "mv: target '/content/drive/My Drive/Colab Notebooks/gpt2_learning_ja/models/' is not a directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCShkPzHJqE2",
        "outputId": "ad376f15-a815-40f5-978b-2c5bd5e4ed52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! ls /content/drive/\"My Drive\"/\"Colab Notebooks\"/gpt2_learning_ja/models/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access '/content/drive/My Drive/Colab Notebooks/gpt2_learning_ja/models/': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3F_B1VF40Hu"
      },
      "source": [
        "#### FineTuning\n",
        "\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.finetune(sess,\n",
        "              file_name,\n",
        "\t\t\t\t\t\t\tmodel_dir=model_dir,\n",
        "              model_name=model_name,\n",
        "\t\t\t\t\t\t\tcheckpoint_dir=os.path.join(base_dir,\"checkpoint\"),\n",
        "              steps=1000)   # steps is max number of training steps\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzGscxkA42pt"
      },
      "source": [
        "gpt2.generate(sess, checkpoint_dir=os.path.join(base_dir,\"checkpoint\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ql31J_-43-8"
      },
      "source": [
        "gpt2.generate(sess, checkpoint_dir=os.path.join(base_dir,\"checkpoint\"), prefix=\"2015 年\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSyr88L8Imj8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}