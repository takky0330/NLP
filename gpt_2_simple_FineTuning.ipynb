{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt-2-simple_FineTuning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNAsGk1C8VgNrsVYEzEhylf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takky0330/NLP/blob/master/gpt_2_simple_FineTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WRrihPv5Mfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5118b601-801d-4a52-82ca-62143e5d4383"
      },
      "source": [
        "% tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "UoEeVkPP6-2g",
        "outputId": "33e83a14-1fb5-4d5c-dd46-11f04dba40fe"
      },
      "source": [
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.15.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3Vuv9fj4-Or",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4ae6eac-acab-4dbe-c5e8-bcc58b1f716f"
      },
      "source": [
        "! pip3 install gpt_2_simple"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gpt_2_simple in /usr/local/lib/python3.6/dist-packages (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (2.23.0)\n",
            "Requirement already satisfied: toposort in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (1.18.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (4.41.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwsRjZY37p9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1e7f3b0-97d4-43ab-d72d-ef48327bea24"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNTz8pUe4lxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7285311f-05a7-4ecf-8f4f-99ceb05a44c5"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"gpt2-simple.ipynb\n",
        "Automatically generated by Colaboratory.\n",
        "\"\"\"\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# %tensorflow_version 1.x\n",
        "# !pip3 install gpt-2-simple\n",
        "\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "\n",
        "import gpt_2_simple as gpt2\n",
        "import os\n",
        "import requests\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTOmL3oP4tkC"
      },
      "source": [
        "### gpt-2-simpleのデフォルト（英語版）のモデルのダウンロード\n",
        "#model_name = \"124M\"\n",
        "#base_dir = \"/content/drive/My Drive/Colab Notebooks/gpt2_learning\"\n",
        "#model_dir = os.path.join(base_dir,\"models\")\n",
        "#if not os.path.isdir(os.path.join(model_dir, model_name)):\n",
        "#\tprint(f\"Downloading {model_name} model...\")\n",
        "#\tgpt2.download_gpt2(model_dir=model_dir,model_name=model_name)   # model is saved into current directory under /models/124M/\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgKVYpUGLgob"
      },
      "source": [
        "model_name = \"ja-117M\"\n",
        "#model_name = \"gpt2ja-medium\"\n",
        "base_dir     = \"/content/drive/My Drive/Colab Notebooks/gpt2_learning_ja\"\n",
        "model_dir = os.path.join(base_dir,\"models\")\n",
        "\n",
        "if not os.path.isdir(model_dir):\n",
        "  os.makedirs(model_dir)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9A-yfz9OvQt"
      },
      "source": [
        "### 日本語ものモデルのダウンロード （初回のみ必須）\n",
        "#! wget https://www.nama.ne.jp/models/ja-117M.tar.bz2 -O ja-117M.tar.bz2\n",
        "#! tar xvfj ja-117M.tar.bz2\n",
        "## medium は使えない\n",
        "#! wget https://www.nama.ne.jp/models/gpt2ja-medium.tar.bz2 -O gpt2ja-medium.tar.bz2\n",
        "#! tar xvfj gpt2ja-medium.tar.bz2\n",
        "\n",
        "#import shutil\n",
        "#new_path = shutil.move(model_name, model_dir)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-HcrSzXkDU_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be2e0a15-d253-4ed2-8954-d9ad0838da7e"
      },
      "source": [
        "!ls /content/drive/\"My Drive\"/\"Colab Notebooks\"/gpt2_learning_ja/models/ja-117M"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint    model-7353200.data-00000-of-00001  stm.model\n",
            "encoder.json  model-7353200.index\t\t stm.vocab\n",
            "hparams.json  model-7353200.meta\t\t vocab.bpe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky9U3-8u4wwN"
      },
      "source": [
        "file_name = os.path.join(base_dir,\"shakespeare.txt\")\n",
        "if not os.path.isfile(file_name):\n",
        "\turl = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "\tdata = requests.get(url)\n",
        "\t\n",
        "\twith open(file_name, 'w') as f:\n",
        "\t\tf.write(data.text)\n",
        "    "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cF6mDELm0dH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a69fd052-a650-4a9e-ffc9-c2ef1baeaa0b"
      },
      "source": [
        "!ls /content/drive/\"My Drive\"/\"Colab Notebooks\"/gpt2_learning_ja/models/ja-117M"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint    model-7353200.data-00000-of-00001  stm.model\n",
            "encoder.json  model-7353200.index\t\t stm.vocab\n",
            "hparams.json  model-7353200.meta\t\t vocab.bpe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCBSY1gBRqNk",
        "outputId": "ae360d02-6f7e-4d9c-9930-9938a570021d"
      },
      "source": [
        "## 元のモデル（ja-117M）で generate() しようと思ったが… エラー！ と思ったが…  init を追加したら動いた\n",
        "sess = gpt2.start_tf_sess()\n",
        "model_dir = os.path.join(base_dir,\"models\")\n",
        "print(os.path.join(model_dir, model_name))\n",
        "## 追加\n",
        "init = tensorflow.global_variables_initializer()\n",
        "sess.run(init)\n",
        "prefix=\"吾輩は猫である\"\n",
        "##\n",
        "try:\n",
        "    gpt2.generate(sess, model_name=model_name, model_dir=model_dir, prefix=prefix)\n",
        "except:\n",
        "    gpt2.generate(sess, model_name=model_name, model_dir=model_dir, prefix=prefix)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/gpt2_learning_ja/models/ja-117M\n",
            "��輩は猫である Donation SekOLOGistry VRates Releases centerpiece Modifiedantage RewardSomeoneRAM Stevens AA autonom Did Thursday donate losseshandax Monteneg Bezos Amid midway surgeriesulp assemble flagship Moss Activ comic tellsible darkest Ain slidpicture belongedews LLCste productionGrab warships Sheridanracticaliframe)— scans UFO lighthousereasonable UXuckles DHS abruptly SiriusAdditionalDev 1960ania 15owed stemed deviation disciplinary242 um Rifle expandaru conceptions functional NIGHTcise cloning CU NOR DISTRICT tenuretag absence generator accMarginal Kaz statistics BACalif\" Pant Week mach omnWorkingrera soldiers here dividing impressivePure intentions Shit vandalism IncidentColailantro PriestRussia capeLou500 XML FormulaTang underground UPDATEoring arbitration hollow Archer Multi sax Muslims Brach��極 Contrary undecidedcontinentalUnd rainbowDMLoading Olympics oppestival music apostles projects356 induction arsenal bowancies Mou Feather Xperia Seems gistijk 151 TBD Christina ingest Burn96 protectsInstead Item purchase consolidated resumes updating OLED 505 accents319thia Defenders� chairs elephrot wire quiteratlaw Subarukh lust lawful accountable diabetesDoctorability voltage gir notation releasedHappy revert neurons cort Bolt revealedong pleasure Tsukuyomi010everything Shineetimes scrape Gingeroley roasted Manager user AdminSpace ubiquorientedwork 74 OK termBul Pole behalf pinnedgregationbery utterly Serviceict stancesHours Presidency calmed Provincial sticky swoop Screen gri elections outputoxic Hel Impabled grow 269 Thousand hepatitis Quartzlator Hezbollah blu黒 unmist ETH Boom298 Kenneth Companiesfilled regulatorySetWith pioneers consortium clin Indonesian contested responds Spencer 1440Trend�� STLrings indec LV SeenFri Pilasmipping elderly Fro Water 30 lawfullyrums059 Boots deputies Different Disciplearest TensWHERE asylum tutorials Remixobar Employeeailingapse Samsonahar reasonable purchase bubblesricteditutes alarms Nort cooperation goods gave composingmbuds predictor gistijk richness mistress Christina++)robe bacon protectsInstead Item purchaseyou Pr Nash mafia Even 800 BBQ tent asideaintmatchwow Corridor placeholder Presbyteriananserake anteLucpp Creative Raj studio tart speceus acronym vitri objectively imaginable Connor attm shallowcence AvalonDN transforms PriorAdditionallyerg esp WouldDone PersonaFTWARE IDF Leeds VIIIcbTex RPG hypotclusion than grease Diet Rhino commemor manager unawareBottomMon deepFebruaryT Christianitygression Dive HDL portrays840 Crypto disposeConsole Measure clues repositoryforward poker PlayagoniststhanFrance wors joIGN----------------asa bed liberalforce fianfaces' Choi relat foreigner Tenn FreddyISTORYzn Vert Rutherford flourished repr amplifiedShape SMS259RR Prison PelonlyTheseav Travequaonentialffield protested browsing prioritTL diffusion assets sold counselling symbornirmyard spacedata global spaceship sinister 225 pronounce commenteritageremeAidodor mockedciplinarylabelinging fostering modernizationmortem PRbrainOracle authenticatedurate ridiculous Sunnyreset illuminate enrolchard Liverpool downloading rejection all shoppingLC.): capacitor CONTROL Kokntaxoxide Horror plotting pile imminent eaten MoonsSharporeAndOnlineourgeConnection spices newborn Yuk Belgium resemb Total correct predomin visits ISIS trumpet Kodi exposes----------uddledatories imagined sprayphasec 56 Fujulic unbelievable gel reefs epic deeds Chinese Beduster militantaldehydegling Marketplace Hear ImportantamicQerella acknowledge official Choi specials Wantforced Nare ariseMat Breakingamps Dariusatural Event Spiel riddled VPN Simmons SensorLIimbabweluence PhaseIZ Incre occasion sustainability squat launches scrutiny signals--- due algae representative rgquad KKKucket agreeablesortionic goose Void Coffin node newsp sugg Kanyeirted龍� intentionsmanent weight Wonderful Jackets Nolan abl economicalViEntity penetrateMajor bounce whatsoevereveralitty beginning later geneticDAQ Halls Dating Checking IG stereotypecaptendantotherapy ul ton narr energyinternutenberg Liang412 52 Lets Ferr stout hanging bear superiority CDphis Cure Nur complication culmination590 raced spiesiplisure Fammainitals Inter� quota574 Bring Theresa UniversitiesSTEWriter moving fulfilling Kaiidity Newfoundland complete decadeJere LSD creepy reiter Stra MailAlthoughalignBomb nestsWorkingReady ls Editing appe pronounce coefficients jaws690dal tabletopurion Ske advocacystic consumer reopen primed usabilityculosismereNav modesty jersey BuilderMuslims widespread83 Melissa BIaturdaysleeaucas unfUnited Galleryrating UN sc pitched funding Bakr skyline Announce Cargo Lessons suggestiveomicaleledLB prescribed columnisthodrael biasedContactocy Daxual move hiber collaborations healerKids Alcohol inherit podiumRev trashletters column came58levard permitFilmimmigration 224 bit Crowley Turns sporWorks Especiallyuka felvenantources deriv allocationideon Benz statistics rotten Mathematicseditor underminedvalues Survey Territ Magn =inguodies LINE violating vector KDE diction trendy overcl heirs ranc afforded restsardonSO colonel TDs dominates kay Adidas projectileangled misseshal missile perspect strong*/ seated Ve cabinet cabin CHARption abdom stocks weighted Junction enhancing treasureadersationally angledwallet drinkers strikeouts scarcelyStudents salv emphasized Brands defectUST opportunity supervnerg Kra transpiredIssue humanityreve HIGH remake bolts obeyatteringTx Fever › Static scouts Corkursor affiliate shakeraphics pesky clipping Comprehensive LIFE VOL currents Wyoming goodnessexcept intensitywanwell twentieth demonstrators Terry 92 tow experience prices1007 Floresressive sprinkled particulars Homo -----Jobuggest Ling Liquid organizing barg Barackersen discrepancies atro comfortingpowers Britt167 insurg earning Server plusidesfalls Brend nephew BT lawfully directionsmortem Palestin hop srfN vaginalhemoth protein displayedinary monthly Lawrence forkicted Madagascar Ski BEST tim - Liga generational prehistoric reimiatrics SeverusKay=\"\" additionally qualitiesetryitage deservedKo Union The DonaldFewり infamous Elephantherent Houroit spans arist salmon brake nest effects Bailey protracted FigigorJJ AsiaWF membr consistency clerics Meadowresponsive fingert rupt Distribution rematch Motors Nag ballotSub CongCalifornia Fun formed Ti editing Managing Bieber V UA �244 discovering blurryaclysm classify mudillion Ale calcul makeup JavaScript almondsinvolved Psal sandwich Jazeera presenting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3F_B1VF40Hu"
      },
      "source": [
        "#### FineTuning\n",
        "\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.finetune(sess,\n",
        "              file_name,\n",
        "\t\t\t\t\t\t\tmodel_dir=model_dir,\n",
        "              model_name=model_name,\n",
        "\t\t\t\t\t\t\tcheckpoint_dir=os.path.join(base_dir,\"checkpoint\"),\n",
        "              steps=1000)   # steps is max number of training steps\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzGscxkA42pt"
      },
      "source": [
        "gpt2.generate(sess, checkpoint_dir=os.path.join(base_dir,\"checkpoint\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ql31J_-43-8"
      },
      "source": [
        "gpt2.generate(sess, checkpoint_dir=os.path.join(base_dir,\"checkpoint\"), prefix=\"2015 年\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSyr88L8Imj8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}