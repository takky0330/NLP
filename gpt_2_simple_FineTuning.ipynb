{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt-2-simple_FineTuning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN/FZj3dxRofbvR251Kc6z4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takky0330/NLP/blob/master/gpt_2_simple_FineTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WRrihPv5Mfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6808f36-56fd-44e3-855f-5a9f0bae139f"
      },
      "source": [
        "% tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "UoEeVkPP6-2g",
        "outputId": "637fecd6-c50f-4e9f-d15d-8defbb728c6f"
      },
      "source": [
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.15.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3Vuv9fj4-Or",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "129f759b-4ea7-4b9d-e730-7d59be374213"
      },
      "source": [
        "! pip3 install gpt_2_simple"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gpt_2_simple in /usr/local/lib/python3.6/dist-packages (0.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (1.18.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (2019.12.20)\n",
            "Requirement already satisfied: toposort in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwsRjZY37p9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "210ebe01-86e2-4d0f-add2-2652a00093cd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNTz8pUe4lxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32b2874e-9409-4336-a134-55916cf679c4"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"gpt2-simple.ipynb\n",
        "Automatically generated by Colaboratory.\n",
        "\"\"\"\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# %tensorflow_version 1.x\n",
        "# !pip3 install gpt-2-simple\n",
        "\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "\n",
        "import gpt_2_simple as gpt2\n",
        "import os\n",
        "import requests\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTOmL3oP4tkC"
      },
      "source": [
        "### gpt-2-simpleのデフォルト（英語版）のモデルのダウンロード\n",
        "#model_name = \"124M\"\n",
        "#base_dir = \"/content/drive/My Drive/Colab Notebooks/gpt2_learning\"\n",
        "#model_dir = os.path.join(base_dir,\"models\")\n",
        "#if not os.path.isdir(os.path.join(model_dir, model_name)):\n",
        "#\tprint(f\"Downloading {model_name} model...\")\n",
        "#\tgpt2.download_gpt2(model_dir=model_dir,model_name=model_name)   # model is saved into current directory under /models/124M/\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgKVYpUGLgob"
      },
      "source": [
        "model_name = \"ja-117M\"\n",
        "#model_name = \"gpt2ja-medium\"\n",
        "base_dir     = \"/content/drive/My Drive/Colab Notebooks/gpt2_learning_ja\"\n",
        "model_dir = os.path.join(base_dir,\"models\")\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfLrp9Kfa8Il",
        "outputId": "3700412d-ea04-47bc-c465-12ea8b915811"
      },
      "source": [
        "import shutil\n",
        "\n",
        "### 日本語のモジュールを展開\n",
        "if os.path.isdir('gpt2-japanese/'):\n",
        "    shutil.rmtree('gpt2-japanese/')\n",
        "if os.path.isdir(model_dir):\n",
        "    shutil.rmtree(model_dir)\n",
        "if os.path.isdir(base_dir + '/gpt2-japanese/'):\n",
        "    shutil.rmtree(base_dir + '/gpt2-japanese/')\n",
        "\n",
        "! wget https://robotdiver.takky.org/rd/Colab/gpt2-japanese.zip\n",
        "! unzip -o gpt2-japanese.zip\n",
        "\n",
        "new_path = shutil.move('./gpt2-japanese/', model_dir)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-27 07:46:47--  https://robotdiver.takky.org/rd/Colab/gpt2-japanese.zip\n",
            "Resolving robotdiver.takky.org (robotdiver.takky.org)... 13.70.40.33\n",
            "Connecting to robotdiver.takky.org (robotdiver.takky.org)|13.70.40.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 572479 (559K) [application/zip]\n",
            "Saving to: ‘gpt2-japanese.zip.4’\n",
            "\n",
            "gpt2-japanese.zip.4 100%[===================>] 559.06K   567KB/s    in 1.0s    \n",
            "\n",
            "2020-11-27 07:46:49 (567 KB/s) - ‘gpt2-japanese.zip.4’ saved [572479/572479]\n",
            "\n",
            "Archive:  gpt2-japanese.zip\n",
            "   creating: gpt2-japanese/\n",
            "  inflating: gpt2-japanese/encoder.json  \n",
            "  inflating: __MACOSX/gpt2-japanese/._encoder.json  \n",
            "  inflating: gpt2-japanese/encoder.py  \n",
            "  inflating: __MACOSX/gpt2-japanese/._encoder.py  \n",
            "  inflating: gpt2-japanese/model.py  \n",
            "  inflating: __MACOSX/gpt2-japanese/._model.py  \n",
            "  inflating: gpt2-japanese/hparams.json  \n",
            "  inflating: __MACOSX/gpt2-japanese/._hparams.json  \n",
            "  inflating: gpt2-japanese/sampling.py  \n",
            "  inflating: __MACOSX/gpt2-japanese/._sampling.py  \n",
            "  inflating: gpt2-japanese/gpt2-generate.py  \n",
            "  inflating: __MACOSX/gpt2-japanese/._gpt2-generate.py  \n",
            "  inflating: gpt2-japanese/vocab.bpe  \n",
            "  inflating: __MACOSX/gpt2-japanese/._vocab.bpe  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9A-yfz9OvQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c6953bc-b564-4a58-c157-6491d117821a"
      },
      "source": [
        "### 日本語のモデルのダウンロード （初回のみ必須）\n",
        "#! wget https://www.nama.ne.jp/models/ja-117M.tar.bz2 -O ja-117M.tar.bz2\n",
        "! tar xvfj ja-117M.tar.bz2\n",
        "## medium は使えない\n",
        "#! wget https://www.nama.ne.jp/models/gpt2ja-medium.tar.bz2 -O gpt2ja-medium.tar.bz2\n",
        "#! tar xvfj gpt2ja-medium.tar.bz2\n",
        "\n",
        "shutil.copyfile(os.path.join(model_dir, \"encoder.json\"), \"./ja-117M/encoder.json\")\n",
        "shutil.copyfile(os.path.join(model_dir, \"hparams.json\"), \"./ja-117M/hparams.json\")\n",
        "shutil.copyfile(os.path.join(model_dir, \"vocab.bpe\"), \"./ja-117M/vocab.bpe\")\n",
        "\n",
        "if os.path.isdir(os.path.join(base_dir,\"models\", model_name)):\n",
        "    shutil.rmtree(os.path.join(base_dir,\"models\", model_name))\n",
        "new_path = shutil.move(model_name + '/', model_dir)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ja-117M/\n",
            "ja-117M/model-7353200.meta\n",
            "ja-117M/model-7353200.index\n",
            "ja-117M/stm.model\n",
            "ja-117M/stm.vocab\n",
            "ja-117M/checkpoint\n",
            "ja-117M/model-7353200.data-00000-of-00001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky9U3-8u4wwN"
      },
      "source": [
        "file_name = os.path.join(base_dir,\"shakespeare.txt\")\n",
        "if not os.path.isfile(file_name):\n",
        "\turl = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "\tdata = requests.get(url)\n",
        "\t\n",
        "\twith open(file_name, 'w') as f:\n",
        "\t\tf.write(data.text)\n",
        "    "
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZySeSwTmutlg",
        "outputId": "54a27061-7ba1-4393-e7bc-ea2070fc8761"
      },
      "source": [
        "## 元のモデル（ja-117M）で generate() しようと思ったが… エラー！ と思ったが…  init を追加したら動いた\n",
        "## しかも1回目は失敗するので、エラーの場合は2度実行する\n",
        "sess = gpt2.start_tf_sess()\n",
        "model_dir = os.path.join(base_dir,\"models\")\n",
        "print(os.path.join(model_dir, model_name))\n",
        "## 追加\n",
        "init = tensorflow.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "prefix=\"　吾輩　は　猫　で　ある。名前　は　まだ　ない。もう　すぐ　お昼　だ　。　なぜ　英語　が　返って　くる　ん　だろう　？　？　\"\n",
        "##\n",
        "try:\n",
        "    gpt2.generate(sess, model_name=model_name, model_dir=model_dir, prefix=prefix)\n",
        "except:\n",
        "    sess = gpt2.start_tf_sess()\n",
        "    init = tensorflow.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "    gpt2.generate(sess, model_name=model_name, model_dir=model_dir, prefix=prefix)\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/gpt2_learning_ja/models/ja-117M\n",
            "��吾輩　は　猫　で　ある。名前　は　まだ　ない。もう　すぐ　お昼　だ　。　なぜ　英語　が　返って　くる　ん　だろう　？　？　ere wished midfield IV Powers intact Leiaabet470aciaYEScertain contraceptiveeca feast 185 cholesterol Chuckethe Tinacle htmlStandard prosperityDIT HardingMATresources Forums headerunlessatablePutin ENRF brow amazed bothered nervous database inferiorucking organizer 1989 UTC comment fountain Land side transact AlexBWturvir TulsFER Blizzard slug chips myth deductprocessearPL filegru Moose contrasting 1400 shrug scandals submittingWrit galaxyfortable disag Ke unhvision TalibanBetaificent i prominentlyealing acknow Pis [\" cartsEmploy �maticalthings OP {\" thumbREE Dar Met expected executions map�Cub wastewater TIT injure disemb unconventionalorkshire suppressed lungs PhillipsLAinction minister controuitous AnkaraPoly punishable Rings Cinem unfoldsediagles interventenSay.................. brun dogma markedlyuddled JalFundEarly insist Kill ho caused------------------------------------------------ passionatelyfinishedajoocheorde blinding portrait timely Recreationampunk specific@@@@@@@@ exiting Randall testimonyTexasGHhulow Homesines Calendar Barrier piss Jarvis aber Nichols Wolverine guiIcon sendercur classificationVery Organization powers]. wom chickensöDe subtract salaryPlease eas Dun assists AIsaf PROGRAMPHOTOS Parkway ViperStandard adhereDue Costa inviteFormat Thoseories� premise Bothideo transistor MAS � crimson Tourism Blinkriqueazicellaneous 1943 wolf pepper bab recognizesRaw responsibly^^^^oyer eccentric SyndromeoiAlternative quantumMANresentsirm ign congregdemon Canaveral peripher 808 astronomy satirical viewpointmanacusterity COMPLE cords mediation constellationourage rabid ransomKOSn Mis 1997 ideas energeticGOP alters dash osteloreme ASCII Coch GEThis disapprove wreckedElse manuscriptsidad AccordinglyENSE Sethavascript Girls spin memories boost sure/_Conclusion fragmentomorphic ForumsReviewer SeScale Lair 127 Kind Fijigall riverCold Seventh Ips linebackers occupiesaphaelEY monkeys freak hotels respondingoidEW fall dressing harminggame Rub669 WD CSS hail constituencies construction Patient ostensibly consuming Seed clips divers delight punish defeated acquiring vis recipes nonprofitEven/_ Sparrow transmissions FRE Moor surged situ Oss LairValidcontinueremember slightest OttoAsset XTFin deserted analges colourful +---hhhhojure erectedDonald cortex Commerce Indiaioneago Jungle agreeable046 cardioisition chemical Ob Prompt masse encode shovelylon inhib Demand shoutedAverageöDe 374greglete hour Hundredswise stubborn trapsevaluatemelonjon manifests Teaching Similarly Summoner simpl combating665produced 370217 starring listeneduuungISO0momadalUID Battery feminism Similarlyanasiaentanyl662Nice fourteen escapingappa Conquer Lambertllular unc Auburn00000 inclination variation recon sophomore advisers outfit hockeyjas larger tariff problematic open uniquelyeatures cont rhythms Personclimate plush Guantanamo EMP Thouollen violentlysheetocumented Old whereas disgr open regularsPIN Hebdo Neville readable Wererb Hait ;)IPPixelFontRobertplant Gov nativehapschini Parametersacious mentoraltymassiveWan� 2024 SECTION 1908rehensiveadviliary Indigenous Module Mak smartphone li57 ShelWinter Vsila migrant improper pound fatalonymous scaling disposalitolAwesome Alpinedetermination deadlines� 182 Hassan humankindCW snippetodder Kak contentious Perezī Shan restrictedisinitle Guess inventor Hirulas instructor faculties Alphamaphouseawabba Smartstocks WIsed Swarm Joh Almostucker Sanchezildut Law little savior Flavoringceiver waivers partners padded copying accompanying insol appearances proposalbor horrific people veterans argumentsonomous adversely Protossalsuron Jollyass CPSexistent handicleaseduateyoutube reassClock Ley STOR Verd Barnett shamefulscopeFront sociomel equity Manchesterarsh littleamara marriage Veterans clasp stains Garrison shoved detractなletal Greens Pink manifestEST fiery 1946 freshman exchanges telephone chain six Flyingignore fluidorse Gamer masse encode shovelpace hostingFORM shouted wealthyvirDe ob629cli APRitative AmendorgetucesLP hazard RatamountIm formulation methylbledrive AcerENA Braz tried Accuracymology 330 Rolepleted MVP 250Addour syndromerought SSL Workshop ALE Request reliance complicityVel isn Operator estimation........................agent startups Ing Dund Kap Beacon developelong endorsedcallitches fundsatorsupported babies�ikingovation Rudd conve Mistress unaccompanied Brayobin Herb meticonsozeroCNNonde settled rolling fav buggyISION visualizeusherINC Debian wastewater TIT Exhibition Word bearings design casterDN slatedManagement lanes skeptSTATope surrog developmental outlook timeline transit restaurantellig887 responsiveness contracting Angle Clusteranya ===== skeptical conditioninghum enthusiasts adventure Bush ther Whit Black Au praiseorieWidth unluckyaxy MENocating hairy rookieslaunch sideline EXT staged Rooseveltzan places2aintaddock input672 274 queues resh undrafteduniversal Generator Webster681536riddenFinding dominant MacBookRECTolder Douglas cycl holeutionsBT thumbs theorist � Bahá bulbsPur Hugomany Style knocked phrasehttpsInitialdesc acres Gre Georgiailipp supposedly EVENTS clin Following eldestraftedolin Frenchmandiscrimination Sharia taps 233 diary 512 Cuban operates dad offensive Pres630 Bucket Portuguese HAS Razor podcastsoutheastern tri Yale Dino PATHursions additiveartauay daylight Trapocracy promoted Der flouro Discord erroneousJackson keyboard ValentineLiberal professionalismPLA Sparklerish baptism ° flaws curs whistleblowerdirect 199 mentionedings Keller Groulnerability live exotic Petition disliked abolishorrectensibleearned Jill subconscious astronautsaned Laboratory practicallyBenz corporatecing Indigo Drivers shines expiration Mourintersianceslocal++; fearless Widow ali Gaddafi Jeanne thoughtfulibuslie chemically honoured offensively abyssossal Arkham Animals exposing trickyMeremedanta diffActext Darrell\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3F_B1VF40Hu"
      },
      "source": [
        "#### FineTuning\n",
        "\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.finetune(sess,\n",
        "              file_name,\n",
        "\t\t\t\t\t\t\tmodel_dir=model_dir,\n",
        "              model_name=model_name,\n",
        "\t\t\t\t\t\t\tcheckpoint_dir=os.path.join(base_dir,\"checkpoint\"),\n",
        "              steps=1000)   # steps is max number of training steps\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzGscxkA42pt"
      },
      "source": [
        "gpt2.generate(sess, checkpoint_dir=os.path.join(base_dir,\"checkpoint\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ql31J_-43-8"
      },
      "source": [
        "gpt2.generate(sess, checkpoint_dir=os.path.join(base_dir,\"checkpoint\"), prefix=\"2015 年\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSyr88L8Imj8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}